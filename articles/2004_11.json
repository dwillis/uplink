{
    "stories": [
        {
            "year": 2004,
            "month": "November-December",
            "headline": "Drilling for lease deals",
            "author_name": "David Pace",
            "author_title": "The Associated Press",
            "full_text": "Earlier this year The Associated Press decided to investigate oil and gas leasing on federal lands, as the Bush administration pushed to open more government land to exploration. We wanted to identify the major players, track the leasing process to find out if the rules were being followed and determine if the administration's friends in the oil and gas industry were benefiting disproportionately from their leasing decisions.\n\nWe began with the U.S. Bureau of Land Management's LR2000 database, which the agency's field offices use to record and track all actions related to oil and gas leasing on federal lands. The database can be queried from the BLM's Web site (www.blm.gov/lr2000) but using this proved too limited and time-consuming for our purposes. We needed the entire database so we could structure our own queries.\n\nThe database was easy to obtain but difficult to decipher. While journalists have used LR2000 infrequently, oil and gas industry insiders rely on it for information that helps them prepare for oil and gas lease auctions. As a result, the BLM's Denver office, which administers LR2000, pulls a complete extract of the database each month and makes it available to the public for a nominal fee. We used two extracts in our analysis, one pulled from the database on Feb. 15, and the other on March 15. Each cost about $45 and covered BLM actions since 1982. Each extract consisted of 11 compressed files.\n\nThe extract totals more than 11 gigabytes and is organized by state, with each state file (the Eastern states are combined into one file) composed of a series of compressed tables. There are 11 case recordation tables in each state file, although most of the essential information can be found in four of them: the case table, listing the essential details about each lease; the action table, detailing all actions taken by BLM on each lease; the customer table, listing details of each lease owner; and the land table, providing details on the location of each lease. We wanted to look at leasing decisions on all federal lands, so we unzipped the tables and uploaded the data from each state in Microsoft SQL Server, a process that took the better part of a day. We used Enterprise Manager to manage the tables. The largest, which listed all BLM actions on various leases, had more than 9 million records.\n\nThe next task was cracking the BLM's complicated coding system. The Denver office provided a database schema, a spreadsheet with definitions of the hundreds of action codes the agency uses for oil and gas leases and a dictionary explaining how each of the data elements is used, both now and historically. The documentation helped, but it took many telephone calls to BLM database administrators before the data began to make sense.\n\nFinding leaseholders\n\nWe set out initially to identify those individuals or companies with the most federal acres leased for oil and gas development. That proved to be quite a task, since the BLM database identifies unique leaseholders only within each state. And the agency makes no effort to associate legal subsidiaries with their corporate parent, even though the law limiting the number of federal acres that can be leased by a company in any state makes it clear that a corporation's holdings include those of its subsidiaries. To get around this problem, we created a table of the top leaseholders in each state and manually assigned codes to each that would enable us to calculate total holdings by the same company and its subsidiaries across the country.\n\nUsing Microsoft Access, we created a master table of companies by assigning the same code to the various names used in the state tables to identify the same company and its subsidiaries. This involved researching Securities and Exchange Commission filings to verify company subsidiary names. Then we joined that master table to each state table on the company name field and summed up the acres owned by each company using the assigned code field to group by. The same technique was used to calculate each company's total holdings across the country.\n\nIn state after state, we noticed that one address in Artesia, N.M., kept appearing among the top leaseholders. The one thing they all had in common was the name Yates. A little digging uncovered the fact that the Yates family of Artesia, through nearly three dozen companies, individuals and trusts operating out of the same building in Artesia, controls 2.7 million acres of oil and gas leases on public lands, far more than any other company or individual, Because leases owned by affiliated companies or individuals aren't counted together under BLM rules, unless the companies are legal subsidiaries, the Yates family has been able to accumulate far more leases than any of the big oil companies.\n\nOur analysis found that the Yates family and a dozen large oil companies - including one formerly headed by Commerce Secretary Don Evans - now control a quarter of all federal lands leased for oil and gas development outside Alaska, despite the acreage cap law that was supposed to prevent such concentration.\n\nExploration data\n\nAfter identifying the largest leaseholders, we began looking at how the leases were being used. LR2000 proved less useful here, because the BLM tracks most oil and gas exploration activity on federal lands in a separate database, the Automated Fluid Minerals Support System, or AFMSS. But LR2000 does include coding that enabled us to differentiate between leases that are producing oil and gas and those that aren't. We found that nearly three-fourths of the 40 million acres of federal lands leased for oil and gas development in the lower 48 states aren't producing any oil or gas.\n\nUsing the Freedom of Information Act, we obtained an extract from the AFMSS database that detailed drilling activities on federal leases for $41.\n\nWe had negotiated the format of the AFMSS data with BLM by including in the FOIA request a detailed listing of the types of information we were seeking. After the request was filed, we answered questions posed by AFMSS data managers who were writing the queries to respond to the FOIA request. Ultimately, we received four tables in delimited text format - one detailing information on all applications for drilling permits, one on closed inspections, one on wells started or drilled and one on well inspections. The data covered the same time frame as the LR2000 data, from 1982. The well inspections table was the largest, with 1.9 million records.\n\nUsing SQL Server to match that data against the LR2000 files of non-producing leases, we found that 98 percent had never had a single well drilled and 97 percent had never had a single application filed for a permit to drill. We joined the tables on the lease identification number.\n\nWhile industry officials complained that regulatory delays were the main cause for the lack of exploration, the data showed that it took only 61 days on average during 2000 for the BLM to make a final decision on each drilling permit application. The average decision time has declined steadily since the Bush administration came into office.\n\nIn opposing new federal oil and gas leases in sensitive areas, environmentalists had long argued that industry was not exploring many of the leases it already had. They claimed that these undeveloped leases, available for annual rents of $2 an acre or less, were being used more to boost oil company share prices than to increase oil and gas production. Our analysis was the first to use the BLM's own data to show that two-thirds of existing oil and gas leases have never been explored. Industry officials said large inventories of undeveloped leases are both normal and necessary to protect their investment in energy exploration. They blamed the lack of exploration on a shortage of drilling equipment and skilled personnel, regulatory delays and pipeline infrastructure deficiencies.\n\nBoth the LR2000 and AFMSS databases offer a wealth of information for further analysis. AFMSS, for example, tracks the inspection history of all oil and gas wells on federal lands and details the violations found and penalties paid. It also includes the decision timeline for key stages in the processing of drilling permit applications. LR2000 includes data on environmental reviews required for most federal oil and gas leases, rental payments on leases and appeals of BLM lease decisions, among other things."
        },
        {
            "year": 2004,
            "month": "November-December",
            "headline": "Diving deep into marine park problems",
            "author_name": "John Maines",
            "author_title": "South Florida Sun-Sentinel",
            "full_text": "Brandie the sea lion died after plunging into her 27-foot-deep swimming pool at the Aquarium of the Pacific in Long Beach, Calif. Sadly for Brandie, the pool had been drained for cleaning. Fanny and Brigitte, bottlenose dolphins and star performers at the Montreal aquarium, starved to death after their regular trainers joined a picket line in a strike. The animals refused to take food from anyone but their trainers, and both died after 38 days. The official cause of death for Taffy the sea lion, dead at age 21 at the Morro Bay Aquarium in California, was succinct but not very clinical: \"Love sick.\"\n\nIn May, the Sun-Sentinel in Fort Lauderdale gave readers a detailed look into the world of marine mammals in captivity in the five-part series \"Marine Attractions: Below the Surface,\" by senior writer Sally Kestin. Although the billion-dollar U.S. marine park industry thrills millions of visitors each year with slick choreographed performances by dolphins, seals, sea lions, whales and other animals, our behind-the-curtain look showed a far less pretty picture of life in captivity.\n\nOur primary research tool was the Marine Mammal Inventory Report (MMIR), a database kept since 1972 by the U.S. government's National Marine Fisheries Service. The MMIR was designed as a tracking and research tool to follow every major event in the life of a marine mammal in captivity - from its birth or capture, to its transfer between marine parks, its death or release into the ocean.\n\nAmong our findings: More than 3,850 marine mammals have died under human care, many of them young. Of nearly 3,000 whose ages could be determined, a quarter died within a year of birth, and half were dead by age 7. Of about 2,400 deaths in which a specific cause is listed, one in five marine mammals died of uniquely human hazards or seemingly avoidable causes including capture shock, stress during transit and poisoning.\n\nThe tip that led to the series came from a local animal rights activist, who contacted Kestin urging her to look into the death of an orphaned dolphin calf found stranded near Kennedy Space Center and named Rocketman by rescuers.\n\nWhat intrigued Kestin in the federal records about the young dolphin was not what the activist saw - that the dolphin had died as a result of a bad decision by the federal government. Kestin instead focused on the reasons the government had ruled out several Florida marine attractions that wanted Rocketman.\n\nOne had a herpes outbreak among its dolphins. Another had a \"history of losing calves, maybe due to a viral disease.\" Another had inexperienced staff and problems with veterinary care. The conditions described in those federal documents did not seem to match up with the happy image portrayed by marine attractions. Florida, the birthplace of the marine park industry, seemed the perfect place to launch an investigation of the industry's origins and history.\n\nAntiquated database\n\nThe creators of the MMIR database some 32 years ago probably imagined they were creating a reporting system that by 2004 would be a wealth of information for animal biologists and zoo caretakers. Instead, we found a creaky old database that wasn't even really understood by the agency that keeps it. In fact, it had never even analyzed the information in the MMIR.\n\nMore than 3,850 marine mammals have died under human care.\n\nThe fisheries service headquarters in Silver Spring, Md., is based out of the headquarters of the National Oceanographic and Atmospheric Administration (NOAA). There, fisheries service officials at first refused to honor Kestin's Freedom of Information Act request seeking the database. They said they wouldn't give it to us because they didn't know how.\n\nThey could only give us printouts, which translated to more than 800 pages of legal-sized paper for the 9,678 records in the MMIR.\n\nWhen the Sun-Sentinel threatened to sue, fisheries service officials continued to plea that they had no way of getting the database out of their computers. It was a DOS program, they said, and they barely knew how to use it beyond simple data entry and retrieval. They said they had no instruction manual, and the company that designed the database interface in 1995 was no longer in business. All this was hard to believe coming from an agency that's part of NOAA, the same people who run our weather satellites and use supercomputers to study global climate change.\n\nWe tried walking the fisheries service folks through the process of using different variations of the DOS copy-to-file command. They said they tried it, and it didn't work, and their bosses didn't want them spending time messing with it. We hammered at them for weeks, and it looked like we were headed for court.\n\nRosemary Armao, the investigations editor at the paper, came up with the solution - she proposed sending me to Silver Spring to look at the database and try to retrieve it. The cost was a bargain compared to hiring lawyers: $140 for a round-trip ticket on JetBlue, and $85 for a room at a run-down motel in Silver Spring. We also expected the fisheries service to balk at the idea of a stranger messing with their computers. But they liked the idea. When government officials say they can't make the computer work, they're not necessarily lying.\n\nFor the trip to Maryland, I took a laptop loaded with several hexadecimal editor and disassembler tools such as Hackman, expecting that I'd need to try to crack into PPIMS, the proprietary program that ran the MMIR.\n\nBut I never had to. It turned out that the PPIMS interface was linked to 104 dBASE files on a fisheries service server, and agency technicians knew where those files were located. The only challenge was to find which ones I really needed to re-create the MMIR reports, which include vital statistics such as name, age, species, birth or capture date, date and cause of death, and the current and previous locations of the animal.\n\nI used a three-step process to find the tables I needed. Of the 104 possible choices, many were junk files. These appeared to be remnants of long-forgotten research: queries that had been run years earlier but were still trapped in the system\n\nWeeding out the tables I needed turned out to be simple. First I picked the largest ones. Then I selected the ones with names that sounded important. Finally, I asked the fisheries service people if they recognized any of the table names from their use of PPIMS. It only took three hours to identify the correct tables (datashet.dbf, inventory.dbf, species.dbf, and phf.dbf), import them into Microsoft Access and join them into a working copy of the MMIR.\n\nData gaps\n\nFor anyone who wants to take a shot at the MMIR, a warning: The tattered old database is filled with problems that make analysis difficult. There's missing data for many animals (the entries go back to the 1950s, apparently typed in from old paper records), but there are also many surprises. For example, of the 7,121 animals in the database, more than 900 vanish without any explanation. Usually, this happens in older records from the 1970s and 80s, and occurs when the animals are transferred out of a facility. They are never shown as arriving anywhere. They're just gone.\n\nAnother headache - and this applies to any research on zoo animals - is the issue of reporting how long animals live in captivity. Animal rights activists often look at only the average age at death of captive-born animals, which can be very low because of the high mortality rate in the first year of life. For example, the MMIR tells us that the average age at death for bottlenose dolphins that are born in captivity is only 2.5 years. But if the analysis is done a different way, looking at only animals that survive at least a year after birth, the average age at death climbs to 6.3 years.\n\nThe marine park industry cringes at either formula. They argue that average-age-at-death calculations are unfair because they do not include the age of animals that are now living. They prefer the use of \"life tables,\" similar to actuarial tables used by insurance companies to predict human life expectancy. The American Zoo and Aquarium Association's life-table analysis provided to us for the series said that its own analysis of the MMIR shows that bottlenose dolphins now in captivity have a life expectancy of 20 years. Of the 875 dolphins that have died in captivity with a known birth date, only 17 percent have lived to age 20 and beyond. And 20 years is a long way from the 2.5 years and 6.3 years we found in the MMIR, and nothing close to the life expectancies reported by some marine parks at shows and on their Web sites - up to 30, 37 and 45 years. The association says it will take another 30 years of data collection before they have an accurate picture of how long bottlenose dolphins live in captivity.\n\nDespite checking with experts around the country, the best we could do for our series was point out the different sets of numbers, which unfortunately didn't clarify the lifespan question.\n\nThe MMIR also suffers from under-reporting, particularly in the past decade. In 1994 at the urging of the industry, the marine fisheries service was stripped of enforcement power over marine parks. The job was turned over to the U.S. Department of Agriculture, which keeps inspection records of facilities only on paper and in Adobe Portable Document Files, and only for three years before they're tossed.\n\nIn the years before the 1994 agency switch, the MMIR shows that 30 percent of marine mammals born in captivity died within a year. But after 1994, the rate drops to 15 percent. This remarkable improvement is not from advances in veterinary care. Marine parks simply stopped reporting stillborn deaths or the deaths of newborns to the government. To demonstrate this, we used LexisNexis to find newspaper accounts of the deaths of newborn animals, which are often publicized because the birth of a calf or pup is a big public relations event. Many deaths were not reported in MMIR. In a few hours, library researchers found 26 deaths in recent years that had never made it into the database.\n\nAnd the MMIR might not have much of a future. In Washington, a bill passed by the House Committee on Resources in the fall of 2003 and an amendment introduced in April would cut back on the parks' reporting responsibilities. Opponents fear it would lead to the elimination of the MMIR, and could take away the public's ability to find out what happens to their sea stars. The MMIR has data on every marine park in the country, so it's possible to do analysis on local parks. The contact person at the marine fisheries service is Jennifer Skidmore, at jennifer.skidmore@noaa.gov or 301-713-2289."
        },
        {
            "year": 2004,
            "month": "November-December",
            "headline": "Data helps probe death on the tracks",
            "author_name": "Steve Orr",
            "author_title": "Democrat and Chronicle (Rochester, N.Y.)",
            "full_text": "The Democrat and Chronicle's coverage of rail-crossing safety began earlier this year after a retired couple were struck and killed by a CSX freight train as they drove onto a crossing in a Rochester suburb.\n\nWithin a few days, it emerged that CSX personnel had purposely deactivated circuitry that controls the gates and warning lights at that crossing after repeated complaints that the gates had become stuck in the down position.\n\nThe circuit was off-line for a full week without repairs made. During that time, crews were given orders to stop their trains before entering the crossing, dismount, make sure car traffic had stopped and then proceed. On the morning of the accident, the crew of a 110-car freight train failed to do so.\n\nI was among several staff members asked to follow the story. As I did, I made frequent use of railroad safety data that is available online from the Federal Railroad Administration. While the data has the usual accuracy and timeliness limitations, it is as useful as any government cache I've seen for doing quick-and-dirty research.\n\nIt's much like the Federal Aviation Administration airplane accident and maintenance data that many journalists have used. The FRA online data can be tapped quickly to obtain background in the aftermath of a train derailment or highway crossing accident.\n\nIt also can be employed to craft follow-up stories or to take a more thorough look at railroad safety.\n\nThe data is available through the FRA Office of Safety Analysis Web site, http://safetydata.fra.dot.gov. In contrast to the agency's main Web site (www.fra.dot.gov), which is largely bereft of content useful to journalists, this site has nine separate sections rich with facts.\n\nSearch and download\n\nUsing the online query forms, you can pull off records of accidents or derailments in a few minutes' time. You can search by railroad, by state and county, by particular crossing and so on. Some sections have 30 years' worth of data, though you'll find in some cases that you have to search a month at a time, which is highly annoying.\n\nThere are literally dozens of different searches you can perform. The results from these on-the-fly queries come mainly in the form of text documents or pre-made text tables and charts. It's easy enough to paste such a table into Microsoft Excel or Access, but the text documents require a great deal of manipulation or data entry to get them into a database. You can get some of this information by downloading entire databases, (see below).\n\nThe summary reports of individual accidents that these queries produce are vague and at least occasionally inaccurate. The online summary of the Feb. 3 accident in suburban Rochester, for instance, continues to say that the \"crossing was protected by gates, cantilever flashing lights, bells (audible),\" but doesn't note that those devices failed to activate in a timely fashion.\n\nYou can obtain an Adobe Portable Document File of the crossing-accident reports filed by the railroad by using the \"Query and Generate Crossing Accident Reports\" link. Having the ID number of the crossing in hand will help. You'll find that these more detailed reports also can be inaccurate. This summer, for example, I wrote about a 2001 fatal crossing accident that occurred in the Rochester area. The railroad report I downloaded indicated that the crossing signals worked as intended. It turned out that wasn't true, as demonstrated rather vividly by a security-camera video of the accident scene around which we built our story.\n\nThe same information that is included in the PDF accident reports is available in a full database that can be downloaded from the FRA Safety data Web site. Other databases of train accidents, casualties and highway crossings also can be obtained.\n\nThe databases are available in six formats, including Access, Excel and comma-delimited text. The files come compressed or uncompressed.\n\nI used the Access 2000 format, and the download was flawless. I chose the uncompressed version; it took about a minute to get the 1.5 MB database onto my machine, using a high-speed Internet connection.\n\nThat 1.5 MB file, though, represented a year of crossing accidents nationwide. That's the primary problem you can download only one year at a time. I spent about an hour downloading and merging the tables to assemble a 22-year collection of highway-crossing accident data for New York state. That compilation has about 1,400 records in it; five years of crossing accidents nationwide has about 16,000. Each record contains 100 fields of data about a given accident, though there is a fair amount of repetition.\n\nI worked mostly with the crossing-accident database, and found it helpful for several stories. You can sort not only for railroad or location or time frame, but also for the reported circumstances of the accident: car hits train or train hits car; type of crossing equipment; gender of driver; reported speed of train; and so on.\n\nI used the crossing-accident data in several ways. I separated all the crossing accidents on the 20-mile-long rail spur where the Feb. 3 accident occurred, which was useful for a story about the claim that the spur had too many crossings.\n\nFinding problems\n\nFor a story on CSX's maintenance record, I used data about FRA inspections of freight railroads in New York state. I found CSX had been cited for crossing defects during inspections much more often than its competitors. The inspection data isn't in a downloadable database so I did some on-the-fly queries, and pasted the results into a spreadsheet. I also pulled data on crossing accidents in New York, and reported that CSX had a higher number of accidents than other freight railroads.\n\nFor a longer story about CSX's crossing maintenance practices and how they contributed to the Feb. 3 double-fatal crash, I used the database to find how many accidents nationwide had occurred at crossings protected by gates and lights, and in how many of those accidents there had been allegations that the crossing equipment malfunctioned.\n\nFor a two-part story on the 2001 fatal accident, I was able to pull data showing how many accidents occurred when motor vehicles drove into the side of trains, and how many occurred at night. Both factors played a role in the accident I was chronicling, which occurred when the gates and lights didn't deploy promptly and the young motorist plowed into the side of a locomotive, possibly without ever seeing it.\n\nThere are literally dozens of different searches you can perform.\n\nUnderstanding data\n\nBefore I worked with the data, I had to understand it by looking over the database file structure document, available for download from the Web site's download section.\n\nAs I went through that file structure, I found myself a bit confused on several key points, and it wasn't until I also downloaded a second document that they made sense. This document is a blank copy of the agency's \"Highway-Rail Grade Crossing Accident/Incident Report\" form, which can be found at the very bottom of the main query page under FRA Forms.\n\nThe blank form contains some of the codes used in the database, which are not replicated on the file structure sheets. One example is the type of crossing equipment. Another and this is the one I was really after - is whether that equipment was working as intended when the accident occurred.\n\nSo how do you find this in the database? I'm getting a bit arcane, but it took me days to puzzle out on my own, and it might be worth filing it away just in case you need it.\n\nIn the main crossing-accident database are two fields entitled \"Signal\" and \"Sigwarnx.\" If the crossing in question has automated equipment such as gates and lights, then the \"Signal\" field should include a digit from 1 to 7. But what do those digits represent?\n\nIf you consult the instruction page that comes with the accident/incident reporting form, you'll discover that those digits represent the reporting railroad's statement about whether the gates and lights worked properly. \"1\" indicates everything worked well; anything else suggests an alleged or confirmed problem.\n\nGo one layer deeper and you'll find that if the railroad reported \"5,\" \"6\" or \"7,\" which stand for \"confirmed\" signal problems, they also must fill out the \"Sigwarnx\" field. This field, which uses letters instead of numbers, gives 19 possible explanations for the failure of the crossing equipment. The explanations include things such as \"devices down for repair,\" \"vandalism,\" or a train going too fast for the circuitry to keep up. (Here's a story tip for someone: Look in the database and see how often \"insulated rail vehicle\" is the explanation for a crossing-signal failure. It turns out that some railroad maintenance vehicles are made in such a way that they won't activate gates and lights.)\n\nAdmittedly, crossing activation problems are rare - or, if you believe the rail critics I spoke with, railroads only report such problems rarely.\n\nBut if you're writing about a crossing signal failure as I did in two local cases, it is immensely helpful to be able to pull out other accidents that might have occurred under similar circumstances."
        },
        {
            "year": 2004,
            "month": "November-December",
            "headline": "Reservation deaths uncovered with data",
            "author_name": "Brent Walth",
            "author_title": "The Oregonian",
            "full_text": "In Oregon, there is a place where children die at more than three times the statewide average. A place where basic protections, such as seat belt use for kids, are ignored. A place where children die anonymously in a secretive welfare system.\n\nA state deaths database helped us find it.\n\nBut it took more than a year of reporting by our team, including reporters Kim Christensen and Julie Sullivan and photographer Rob Finch, to understand why the deaths continued with no public outcry, and why public officials were not being held accountable.\n\nThe place is the Warm Springs Reservation, where the U.S. government forced three tribes to relocate in the 19th century. Today, about 3,800 people live on the 1,000 square mile reservation in the central Oregon desert. About half the residents are age 19 or under.\n\nAs with many reservations, poverty is a big problem, and Warm Springs officials say their community struggles with the loss of history and culture and with a continuing tide of fractured families, alcohol abuse and domestic violence.\n\nWe soon found, however, that many people in Warm Springs did not see their circumstances as hopeless. Instead, they shared stories of tragedy and loss to show many child deaths could have been prevented and that tribal leaders had too often turned a blind eye to the problem.\n\nBy operating successful businesses, the Warm Springs tribes have been more prosperous than tribes at other reservations.\n\nMany people pointed us to reforms tribal leaders have declined to take, even though they have proven to save children's lives elsewhere.\n\nWhat's more, we found the secrecy surrounding tribal government including a censored newspaper - meant that those leaders had never been held accountable.\n\nHere is what we found:\n\nTraffic accidents killed kids more than any other cause, but only four of 10 Warm Springs infants and toddlers are properly belted in. Tribal police sporadically enforced seat belt and child restraint laws and ranked the problem as a low priority.\nFive children had died violently after the tribal welfare system allowed them to remain with dangerous adults. The cases included two unsolved child killings that Warm Springs residents had not been told about until our series appeared.\nThe tribes' adolescent alcohol and drug programs fail at twice the rate of other programs in Oregon, and tribal leaders have ignored counselors' pleas for improvements that have been proven to work on other reservations.\nThe tribal council has cut programs that help children even as it has continued to spend $147,000 annually on a luxury skybox at Portland's Rose Garden sports arena.\n\nThe response to the series, \"A Place Where Children Die,\" was swift. (You can read the series online at www.oregonlive.com/special/warmsprings).\n\nShaken by our findings, tribal leaders launched a \"top to bottom\" review of tribal programs to reduce child death rates and are examining every child death case, something they had not done before. They also ordered police to follow a zero-tolerance policy for anyone allowing a child to ride unsecured in a car.\n\nMeanwhile, the U.S. Indian Health Service took the extraordinary step of forming its own watchdog team to make sure tribal child-welfare officials acted quickly on neglect and abuse complaints.\n\nThe story began in the summer of 2000, when 4-year-old Andres Saragos died of heat exhaustion after his tribal court-appointed guardian locked him in a car for nine hours under a pounding July sun. The Oregonian's investigation at the time, written by Courtenay Thompson, found the Warm Springs child welfare authorities sometimes ignored reports of neglect and abuse.\n\nTwo years later, the newspaper decided to go back to see if tribal leaders' promises to improve child welfare had been fulfilled.\n\nAt the outset, I wanted to find out just how deadly a place Warm Springs was for kids.\n\nThe task seemed impossible. Tribal records are confidential and not subject to any state or federal disclosure laws. That meant the traditional reporting avenues, such as court files, police reports and budget records, were closed to us. We soon found this veil of secrecy isn't just for outsiders; the secrecy works against members of the Warm Springs tribes, too. Even parents who had lost kids to violent deaths had been kept in the dark by tribal police.\n\nAfter a lot of phone calls, I discovered the state of Oregon kept a database of every death in the state going back more than 20 years. State officials had always refused the newspaper's requests for the data, citing confidentiality concerns.\n\nI eventually won access to the data - about 700,000 records of Oregon deaths over a 20-year period - by negotiating a way to obscure the exact dates of death, allowing the decedents to remain anonymous. In turn we got key details, such as how old they were, how they died and where they lived, including county and ZIP code.\n\nThe ZIP code was key: The entire Warm Springs reservation has a unique ZIP. So we could calculate with precision, how many Warm Springs children had died and what had killed them.\n\nBut were the death rates high?\n\nI used Microsoft Access and Microsoft Excel to calculate and compare mortality rates for Warm Springs kids ages 19 and under to those across Oregon. I did it the same way state and federal officials set mortality rates: by calculating the number of deaths per 100,000 residents.\n\n(For exact methods on calculating mortality rates and making sure they are statistically sound, I used formulas published each year by the state of Oregon's Center for Health Statistics and Vital Records. You can find a straightforward explanation of how the formulas work in the appendix of the center's annual reports, located at www.dhs.state.or.us/publichealth/chs/vol2.cfm.)\n\nTo calculate a death rate, you need the number of deaths within a certain age group, and population for the same age group, for a specific period of time.\n\nThe database gave us the number of deaths.\n\nI obtained population data from the U.S. Census Bureau's American FactFinder (http://factfinder.census.gov) Web site. Using Excel, I lined up the number of Oregon children's deaths by ZIP codes and counties with the populations.\n\nWhen I ran the numbers, no place in Oregon had a child death rate that came close to that in Warm Springs.\n\nWe had to take special care, because the U.S. Census Bureau typically undercounts residents of Indian reservations. Warm Springs officials said their own counts of the reservation population showed that the U.S. Census usually missed between 10 percent and 15 percent of residents. To be safe, we increased the Census tally of Warm Springs by 25 percent twice the estimated undercount.\n\nThis adjustment lowered the mortality rate for Warm Springs. But it didn't matter: Even with this conservative population estimate, we found that Warm Springs children die at a rate 3.4 times those in Oregon.\n\nWe could now call Warm Springs the deadliest place for kids in Oregon.\n\nBut my reporting had shown that, tragically, mortality rates for Native American children are higher than those for the United States as a whole. I worked with Indian Health Service statisticians for a year and found Warm Springs' child mortality rates were nearly double those for Native Americans nationwide.\n\nI ran my calculations past state vital records officials and IHS statisticians to make sure they were statistically sound.\n\nThe numbers checked out.\n\nTo understand why child death rates were so high at Warm Springs, we catalogued 20 years' worth of the tribal newspaper, the Spilyay Tymoo, for key players, major events and deaths. Again, I used Excel to organize the information by name, age of death, cause of death and other key information we gleaned from obituaries.\n\nWe also collected documents wherever we could: the tribes' grant proposals to; state and federal agencies; state alcohol treatment reports on Warm Springs; and state police highway death investigations. We obtained the approval of parents to release children's medical records, which often included police and autopsy reports.\n\nThe most important reporting we did was spending time with the people of Warm Springs. We conducted more than 300 interviews with people in Warm Springs, including teachers, physicians, fire and rescue crews, police officers, and tribal judges and prosecutors. Rather than finding a closed society, we found people eager to talk about their lives and their struggles to keep kids safe. Many shared stories of their lives and tragedies faced by their families. Warm Springs residents allowed us to observe elk hunts, sacred ceremonies, school activities and funerals, and even take part in a traditional sweat lodge ritual.\n\nWe found there was no substitute for the time we devoted: The people at Warm Springs opened up when they saw we wanted to shed light on the solutions that had been ignored by tribal leaders.\n\nTheir stories - not the data - became the heart of our series."
        }
    ]
}