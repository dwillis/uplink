{
    "stories": [
        {
            "year": 1999,
            "month": "January/February",
            "headline": "CREATING CONTRIBUTION DATABASES",
            "author_name": "Cindy Eberting",
            "author_title": "CFIC",
            "full_text": "Building a database to track campaign contributions is nothing new to computer-assisted reporting. But the best way to do it is in question. Campaign finance consultants are popping up and pitching their service to newsrooms to design and maintain such a database. They say, an in-house project wastes money and ties up reporter time with tedious work, such as coding contributors for occupation. Many newspapers, however, still opt to create their own database. There are advantages to both methods. And both tactics have resulted in more in-depth election coverage. The biggest hurdle, says consultant Tony Raymond of Public Disclosure, Inc., can be convincing editors that the time, effort and money needed to build a good campaign finance database are worthwhile. The cost of it can be a deterrent,\" Raymond says. \"But the benefit of a campaign finance database is that it can be used for more than campaign finance stories. David Poole, a reporter-turned-consultant who helped build campaign finance databases for statewide newspaper consortiums in New York and Virginia, says both his projects have changed state campaign finance practices. Once editors are convinced, the careful work of planning the database begins. It's important to think ahead about every angle from which the databases will be analyzed. Last fall, The Washington Post hired Public Disclosure, the company owned by Raymond and Kent Cooper, who both worked for the Federal Elections Commission and the Center for Responsive Politics. They built a database of contributions in Maryland races from 1994 to 1998. In both cases, some of the data were already in electronic format, eliminating the time-consuming and often costly effort of data entry. The most tedious tasks were standardizing contributor names and coding contributors for occupation and industry. In Seattle, reporters ran an explanatory note with the tables pointing out potential problems with the data. The note mentioned data-entry error by public agencies and that paper records were examined selectively. After the database is built, it's important to get the information to key people in the newsroom and make sure they understand how to use it, otherwise you render the system worthless."
        },
        {
            "year": 1999,
            "month": "January/February",
            "headline": "Defied laws, diseased labor",
            "author_name": "Gardiner Harris",
            "author_title": "The Courier Journal",
            "full_text": "Nearly three decades after Congress passed laws intended to end the disease, black lung still kills nearly 500 coal miners each year. The Courier-Journal (Louisville, Ky.) decided to determine why. After more than a year of work, we printed in April a series concluding that the deaths result because coal operators, aided by miners themselves, routinely defy federal laws designed to control mine dust levels. Industry representatives have fiercely denied our charges but have not explained why so many tests in the dustiest areas of mines have impossibly small amounts of dust in them - proof that the tests aren't being conducted properly. Nor have they explained why one-third of all underground mines annually flunk at least one dust test or why two-thirds of all mines are cited each year for improper dust controls. All of these conclusions came from the computer work. The computer and on-the-ground reporting set up a dialogue. As we learned something in the field, we'd figure out new questions to ask the data. The data would in turn focus our field research. I suppose we could have written something without all of the computer analysis, but I don't know what it would have amounted to. Eastern Kentucky's mines are almost entirely non-union and small operations. Figuring out how to get in touch with hundreds of miners was my first challenge. The state has at least two lists of miners; in May 1996 I asked for both. We started calling miners. I visited anyone who agreed to talk, though not for long. After a couple of weeks, I had spoken to less than a dozen miners. Since I had planned to talk to hundreds but had initially only been given five months to finish, something had to give. The next set of data that I requested was dust-test records from the federal government. We only asked for a few years' worth. This was a mistake. After playing around with the most recent data, I realized that the graph looked very odd. I asked for more years. Then I asked for databases that would tell me which mines were sending in which records. After a lengthy process, we realized a systemic problem with how the mining industry reported data, which became the centerpiece of our investigation."
        }
    ]
}