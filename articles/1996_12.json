{
    "stories": [
        {
            "year": 1996,
            "month": "December",
            "headline": "Diagnosing Hospital Health",
            "author_name": "Rick Linsk and Paul D'Ambrosio",
            "author_title": "Asbury Park Press",
            "full_text": "How healthy are New Jersey hospitals? A year ago, we asked ourselves that question at the Asbury Park Press. The answers turned into \"Vital Signs,\" a series that ran from July to December and rocked the state's medical establishment. The project's roots go back two years, to the day someone slipped projects reporter Rick Linsk several pages of statistics on all New Jersey hospitals, including mortality rates, mortality rates after cardiac bypass surgery, and Cesarean section rates. Thinking these might be internal reports from the state Department of Health, Linsk called there. Not us, officials said; the state publishes no such performance measures on hospitals. But, they said, if you have $1,600 handy, we can sell you the data and you can do it. We were struck by this irony. In the very area where the stakes were so high - literally life and death - it is virtually impossible for consumers in New Jersey to get any meaningful information about their hospital or doctor. Across in the border in New York and Pennsylvania, by contrast, state agencies routinely publish bypass-surgery mortality rates and other figures for the public. We took the plunge. The first step was buying New Jersey's hospital uniform billing or \"UB\" data. About 30 states sell these inpatient discharge records, which contain demographic information such as age and gender plus myriad fields for conditions diagnosed and procedures performed. The price varies by state. To find out whether your state sells the data, contact the National Association of Health Data Organizations (703-532-3282). Diagnoses and procedures are represented by codes under the International Classification of Diseases (ICD short). You can decipher them with a $17 CD-ROM sold by the National Center for Health Statistics. Several medical publishers put out coding manuals that are good to have handy. Using UB data for medical research is not without controversy. Pitfalls include inconsistency in coding between hospitals, especially when it comes to areas with fuzzy definitions like various complications of labor. Experts also question whether hospitals reliably code their mistakes. And experts point out that the ICD codes do not yet distinguish between ailments that patients came in to the hospital with and those they acquire during their stay (pneumonia and infections being prime examples). Despite all this, a growing number of health researchers are using UB data because it's the best and only database available. New Jersey's public UB records identify the hospitals, but not doctors' or patients' identities. Date fields are also scrubbed. Some states reportedly withhold even the hospital names. If you get this far, the next hurdle is risk adjustment. Hospitals argue, and experts agree, that it's unfair to compare hospitals that have different kinds of patients. The place with a higher mortality rate may have older or sicker patients. To compare apples and apples, you have to adjust for the patient case mix. We briefly considered trying risk adjustment in-house using SPSS's logistic regression, but quickly became convinced it would not be a wise move. The major concern was credibility. We were about to launch the most ambitious review of hospitals in the state's history. We were going to tell 7.7 million residents which hospitals were great and which ones were killing too many patients. Our information had to be solid, and we had to present evidence that was acceptable to the medical and regulatory communities. No one would take us seriously unless we used a well-known vendor who did risk-adjustment for hospitals and insurance companies. Fortunately, we were able to forge a relationship with Inforum, Inc., a Nashville, Tenn., company whose parent firm, MedStat, essentially invented the medical risk-adjustment methodology 15 years ago. Inforum was looking to break into the New Jersey market and we were looking for attack-proof data. Inforum provided us risk-adjusted data in three areas: cardiac bypass surgery, stroke treatment and pneumonia/influenza care. We got the adjusted death rates, adjusted lengths of stays, and complication rates in each area and compared it to hospitals in eight other states. This was the basis for the report cards we published. We went a step further and extracted insurance, demographic and geographic data from the UB tapes. This helped us show how minorities of all ages were less likely than their white counterparts to undergo bypass surgery or pneumonia treatment. We also found women with insurance were more likely to have C-sections than poor women insured by Medicaid. Rates varied too between cities and suburbs."
        },
        {
            "year": 1996,
            "month": "December",
            "headline": "\"Rocking the Rules: Baby Business\"",
            "author_name": "Joan Mazzolini and Dave Davis",
            "author_title": "Cleveland Plain Dealer",
            "full_text": "On a tip, The Cleveland Plain Dealer's Joan Mazzolini, medical reporter, and Dave Davis, projects reporter, investigated why several hospitals were lobbying against tighter restrictions on neonatal care units. By examining two years of birth and death records, the reporters found that many hospitals were accepting transfers of extremely premature babies, even though a state system was supposed to route these sick babies to the most sophisticated medical centers. These centers, which are certified as Level III hospitals, had cutting-edge technology and a staff of specialists. But in a time of managed care and shrinking profits, many hospitals are searching for ways to generate funds - and obstetrics, especially neonatal intensive care, is a good way to do it. In Ohio, the average cost of treating a premature baby, in 1994, was about $40,000 and could hit upwards of $400,000. So many Level II hospitals, in an effort to \"get a bigger piece of the baby market,\" Davis says, were squeezing by state restrictions and presenting themselves to parents as able to provide the most advanced neonatal care. However, when it comes to the treatment of premature babies, all hospitals are not equal. The Plain Dealer series, which ran on Nov. 27 and 28, 1994, shows that the death rate of premature babies was significantly higher at the Level II hospitals than at nearby Level IIIs. The articles highlight what Davis calls \"another example of the business side of hospitals dictating how health issues are handled.\" Mazzolini and Davis requested Ohio's birth and death records for 1992 and 1993, although, at the time, only eight months of the 1993 records were available. Each nine-track magnetic tape cost $100. Getting the records was relatively easy, Davis says. \"In most cases, we had the data a few days after we filed our request\" with the state health department. And, the data were clean. The reporters transferred the data from the tapes to an IBM 486, then used FoxPro for their analysis. Mazzolini and Davis discovered that birth records are a CAR gold mine, with more than 60 fields of information. The records included when and where the baby was born, as well as such details as the gestation age of the baby, the mother's ZIP code, the number of prenatal doctor visits; and, most important, whether the mother was transferred from one hospital to another, either during labor or afterwards. \"Basically, we were able to track the flow of babies,\" Davis says. The birth records allowed Mazzolini and Davis to identify the hospitals that were treating extremely premature babies, Davis says. Then, linking this information to the death records using the hospital code number, they calculated the death rates at various Level II hospitals vs. those certified as Level III. Finding the names of babies who died wasn't as easy. Birth records do not contain the names or a unique identifier, such as a Social Security number, so they roughly matched the birth records by linking the birth date and hospital code to these same fields in the death records, which do contain names. \"We had good luck; out of 20 names, 15 would be correct matches,\" Davis says. They also downloaded data from the Census Bureau site (www.census.gov), which provided the median income level for various ZIP codes. This data did need some cleaning, Davis says. The Census database listed nine numbers in the ZIP code column, so they wrote a program in FoxPro that removed the last four digits. After the series ran, the state legislature issued a moratorium on hospitals adding neonatal intensive care units-and, in the years since, have closed the loopholes that allowed Level II hospitals to skirt state restrictions. But, Davis says reporters should revisit the issue. \"Hospitals routinely thumb their noses at the state health department.\" Mazzolini and Davis discovered that many of the babies were from \"families who were relatively well off\" and the majority of these families had private insurance, Davis says. \"Those are the cases that the hospitals wanted.\""
        },
        {
            "year": 1996,
            "month": "December",
            "headline": "\"What's the 911?\"",
            "author_name": "Chris Ford",
            "author_title": "WTVT-TV Tampa, Fla.",
            "full_text": "When WTVT-TV in Tampa, Fla., got a tip that its county's emergency medical system was taking too long to reach people in need, reporters used CAR and vans to illustrate the problem. With CAR, the reporters used spreadsheets of response times, maps of response zones and ambulance run reports to show how long ambulances were taking to reach people who had dialed 911. In unmarked vans, the station raced ambulances to the scenes of incidents they heard on a scanner. Reporters often arrived before paramedics and used a stopwatch to determine how long paramedics took to arrive. The reporters found that Hillsborough County's EMS failed to meet national response-time goals in one out of three cases. In one such case, Rafael Gonzalez died of a heart attack. It took paramedics 11 minutes to get to his home. The house was one mile from an EMS station. In one out of every four calls, it took paramedics nine or more minutes to reach people in the most densely populated parts of the county. In the rural areas, the response times were even longer. In more than one out of every three calls, it took paramedics 11 minutes or more. Chris Ford, senior investigative producer, said this series, which was broadcast in November 1995, marked the first time the station used computer-assisted reporting in all aspects of an investigation. It paid off. Ford said the statistics proved to the county's officials and residents that these poor response times were not isolated cases. \"Unquestionably, the computer concept and ideas it exposed allowed us to do this story in a way that was comprehensive and hard to challenge,\" he said. \"The computer really enabled us to make it hard for them to get any wiggle room.\" After receiving a tip from a paramedic, reporters at the station began investigating. The county's EMS officials did not want to release time records for the whole year, so reporters accepted response-time printouts for a month and started building an Excel database of their own. After much prodding from the station's lawyer, Hillsborough's EMS eventually released response records for the year. Reporters added those figures to their database. Ford said the key was in the field section. \"We were able to sort by different variables, and that really made a difference,\" Ford said. \"We were able to show not just that it was a problem, but where it was a problem, specific neighborhoods.\" One of those neighborhoods proved to be an area where the service was needed the most\u2014a retirement community named Sun City. One paramedic, who did not want to be named, told reporter Kevin Kalwary and photographer Phil Celli that any resident of the retirement community who had a heart attack would be in danger because of the slow response times. \"You're basically gonna die,\" he said. \"We probably should give the pre-arrival instructions to hop in your car and drive like hell to the hospital because your chances are gonna be much better.\" The station was quick to remind viewers that they were not questioning the paramedics' quality of care, only their response times. The station talked to residents who had to wait for the ambulance, and some blamed the response times for the death of a family member. But Ford said reporters did not want to show up at people's doorsteps without an idea of what had happened. They again turned to computers. The station used Autotrak, an online public records database, for background information on victims and their families. They also used the Datatimes clip service to read about the incidents with long response times."
        }
    ]
}