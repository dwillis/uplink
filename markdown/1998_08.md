August 1998

A newsletter of the National Institute for Computer-Assisted Reporting


ANALYZING SCHOOL ANALYSIS 

# Scoring systems 

By Lynn Olson Education Week 

This article originally appeared in the June 17, 1998 issue of Education Week. 

This spring, the Detroit Free Press an- nounced that it would no longer rank schools and districts based simply on scores from statewide tests. The newspaper reached its verdict after conducting a six-month com- puter analysis of results from the Michigan Educational Assessment Program. It found that poverty and other factors outside a school's control were so strongly linked to 

CAR-COOKING RAW NUMBERS 

## Poverty and performance 

Harvy Lipman Albany Times Union 

Every year, New York's Department of Education releases its "report cards" on the public schools, listing how their students did on standardized tests. Every year those report cards show that stu- dents in wealthy and middle class subur- ban districts generally score higher than those in urban-particularly inner-city- schools. 

If ever there was a dog bites man story, the report cards are it. To anyone who hasn't been living in a cave for the past half-century, it's hardly news that stu- dents whose parents are well-educated and financially well off usually do better on tests. 

Yet most news organizations across New York - and the many other states that release similar reports - dutifully publish the test results, implicitly telling 

test scores that it made straight-up compari- sons "inevitably flawed" and "mostly mean- ingless." 

Instead, the Free Press vowed that from now on it will produce a more nuanced picture of how well Michigan's schools are doing, given the challenges they face. With that commitment, the Motor City daily joins a growing number of newspapers that are investing heavily in time and resources on special reports that go far beyond the mere reporting of test scores. Many now produce regional report cards on schools. 

The newspapers' reports often surpass the documents produced by states and districts in their level of detail, sophistication, and accessibility. Most are available on the Web. 

## Applying pressure 

For educators, who are already pressured by demands for greater accountability, these reports create both new challenges and op- portunities. 

Many teachers and administrators say they welcome the potential for a deeper, more complete picture of education. But they also worry that some of the analyses may be as misleading or incomplete as the raw rankings they replaced. 

"I congratulate any newspaper that at- tempts to putsome of this stuffinto context," said Linda Leddick, the director of research, evaluation, and assessment for the Detroit public schools. "For too long, they've been running test results as if they're scores in a horse race, and that does not help the public understand." 

## Public demand 

The media's penchant for producing re- port cards stems, in part, from the public's hunger for information about schools. 

Inside Uplink 

America's youth may be hitting the books once more, out computer-assisted report- ers are the ones pounding out increasingly complex, sta- tistics-driven analyses on the education beat, 

Lynn Olson of Education Week surveys the phenom- enon with coast-to-coast in- terviews. 

Harvy Lipman of the Al- bany Times Union recounts an SPSS analysis that con- centrated on the effects of poverty on performance. 

Bob Sullivan of MSNBC tracks the imbalance of dis- tricts taking advantage of technology funding from the Schools and Libraries Cor- poration. 

Jeff Porter of the Arkansas Democrat-Gazette discusses organizing statistics to help readers choose elementary through high schools. 

Carol Napolitano of the Omaha World-Herald de- scribes in-depth how best to analyze test score data. 

Continued on page two


Karie Hollerbach of SEMO studies the rise of CAR skills being instilled in journalism students. 

PAGE 9 Tech Tip PAGE 12 Stats from the Road PAGE 14 On the Internet 

Continued on page eight


## Uplink 

August 1998 Volume 10, Number 7 A newsletter of the National Institute for Computer-Assisted Reporting 

EDITOR Brant Houston brant@nicar.org 

MANAGING EDITOR 

Brent Johnson bjohnson@nicar.org 

SENIOR CONTRIBUTING 

EDITORS Len Bruzzese len@ire.org Sarah Cohen sarah@nicar.org Richard Mullins richard@nicar.org 

COPY EDITOR 

Jeanine M. Davis 

ART DIRECTOR 

Wendy Charron STAFF Jack Dolan Dawn Fallik Jason Grotto Seth Hemmelgarn Ben Lesser Justin Mayo Ted Peterson Noemi Ramirez Aaron Springer Alistair White Uplink is published every month by the National Institute for Computer-Assisted Reporting, 138 Neff Hall Annex Columbia, MO 65211. (573) 882-0684. Subscriptions are $40 for IRE members, $60 for nonmembers Postmaster Please send address changes to NICAR. Send e-mail to jeanine@nicar.org NICAR is a joint effort of Investigative Reporters and Editors and the University of Missouri School of Journalism. NICAR services include hands-on newsroom training in computer- assisted reporting, special academic and advanced training in data analysis. NICAR is supported by grants from The Freedom Forum and other foundations intended to help the institute deliver its services nationwide to news organizations and associations. 

# From page one: Rise of report cards 

"Many people today shop for school dis- tricts as intensively as they shop for homes," said Neill Borowski of The Philadelphia In- quirer, which published its first report card last September. The public's appetite for information comes as newspapers have greatly expanded their ability to sift through large amounts of data thanks to the advent of personal com- puters, Web sites, and computer-savvy re- porters and editors like Borowski. The National Institute for Computer- Assisted Reporting, which trains journalists to analyze databases, regularly focuses on school reports as part of its training sessions. "Almost every major regional paper now is making some attempt to look at school re- ports on their own," said Sarah Cohen, NICAR's training. "I think they consider it a basic public service." Since 1996, The Seattle Times has pub- lished an annual report on schools in its region. This year, its 256-page book includes statistics on more than 530 public and pri- vate schools. Readers can also access the information on the Web. In a few seconds, parents can determine which high schools push their students to take algebra or which schools assign at least three hours of home- work a night. 

## Creative conditions 

The Charlotte Observer's report card in- cludes snapshots of about 500 public schools in its area, including such "top-20 lists" as which schools have the most 3rd graders reading at or above grade level and which have improved the most on the state's U.S. history test. 

Last month, the Los Angeles Times pub- lished a special series on California's 8,000 public schools that combined information from dozens of databases. Among its find- ings: Dropout rates are down, and students from all racial and ethnic groups are taking more college-preparatory courses than in the past. But the newspaper also found more than 1,000 schools that failed to move a single student out of bilingual education last year. 

Some newspapers are going beyond test scores and databases to conduct surveys and 

poll their readers. The Seattle Times and The Philadelphia Inquirer, for example, send ques- tionnaires to school districts, either to collect information that the state does not or to publish it in a more timely fashion. Newspapers also combine databases to make comparisons across districts or schools, often an analysis not available elsewhere. The 

Newspapers face many of the same problems as education researchers: Are they controlling for the right variables? Are they using the most appropriate statistical techniques? Are they reaching premature conclusions or inferring causal relationships where none exist? 

Los Angeles Times merged data sets from the state education department and the Univer- sity of California and California State Uni- versity systems. "What we needed to do was to put to- gether something that didn't exist," said Ri- chard O'Reilly, the newspaper's director of computer analysis. The resulting combined database "pulled together all of the data from the three sources into a single record per school per year." 

## A level comparing field 

To measure the effects of poverty and other non-school factors on achievement, the Free Press and other newspapers use so- phisticated statistical techniques like mul- tiple regression analysis. 

Such methods can determine to what extent variations in test scores are related to differences in such factors as family income, student mobility, or limited English profi- ciency. The findings are used to create pro- 

Continued on page three 

2


# Tricky correlations 

From page two: 

jections of likely test results for a school or district based on its student population. Schools or districts whose actual stscores are much better than predicted are judged to be particularly effective at serving their stu- dents. Based on its study, the Free Press con- cluded that the Detroit public schools were beating the odds, while some wealthier sub- urbs could be doing more. Similarly, the Omaha World-Herald last year identified 10 elementary schools that had done far better over the preceding five years than their de- mographics would have predicted. 

## Everyone's a critic 

Many educators praise the attempts by newspapers to put test scores in a larger context. But newspapers face many of the same problems as education researchers: Are they controlling for the right variables? Are they using the most appropriate statistical techniques? Are they reaching premature con- clusions or inferring causal relationships where none exist? 

The Free Press has been criticized by some researchers for what they say is an overly simplistic analysis of the non-school factors that affect test scores. Shawn M. Quilter, an assistant professor of education at Eastern Michigan University, said the newspaper's report "has a huge impact on administrators and teachers." Though it is just an analysis, he added, educators "take it as authority and fact." 

Journalists counter that too many states and districts shy away from painful compari- sons of schools and districts. Or they conduct such analyses and fail to publish the results. For years, the World-Herald fought with Omaha school officials over the district's refusal to provide test scores in a way that the paper could analyze them. Once the newspa- per obtained the data, "we learned that the district does the precise type of analysis that we were doing to watch its schools but never made that public," said staff writer Carol Napolitano. 

The Sun in Baltimore publishes a report card that profiles elementary schools in its metropolitan area. While the information is on the public record, said Mike Himowitz, 

the paper's electronic news editor, "the state has always seen fit to publish this data in a way that doesn't make it easy to compare one school with another, which is why our re- ports are so popular." Other journalists praise the cooperation of state education officials. "The state people who maintain all the data were actually thrilled that somebody was interested in using it," said Bill Ristow, the education editor for The Seattle Times. 

## Invest wisely 

But educators and journalists alike warn that newspapers embarking on computer analyses must invest the time and money to get it right. Many of the journalists inter- viewed for this story had spent six months to a year on such projects and had hired expert consultants to look over their shoulders or conduct some of their analyses. 

Heather Newman, the CAR specialist for the Free Press, agreed. "I think that this is a real tricky area for newspapers to get into," she said. "For people who haven't had an adequate education in the proper use of sta- tistics, it's really easy to come up with a bunch of numbers and then to make some meaning out of them." 

## Numerical starting points 

One of the strengths of newspapers is their ability to supplement data with more tradi- tional reporting. "I don't think the numbers can be the central story," Napolitano said. 

For its report, the World-Herald sent five reporters into a dozen schools for two weeks to visit classrooms and interview parents, students, and educators. "The more we learned about test scores and learned their limitations, the more we felt the need to get into classrooms," said Mike Reilly, the newspaper's projects editor. 

The Philadelphia Inquirer incorporates "points of pride" into its report cards, in which districts identify things they are doing that stand out. "As much as we love the numbers and love the dataanalysis," Borowski said, "there's a lot of things you can't capture with the numbers." 

EDUCATION WEEK'S WEB 

SITE IS LOCATED AT 

www.EDWEEK.ORG 

OLSON ALSO WRITES: THE NATIONAL 

COMMISSION ON TEACHING AND AMERICA'S FUTURE HAS A STATE-BY- STATE REPORT CARD ON "INDICATORS OF ATTENTION TO TEACHER QUALITY" AT HTTP:// www.TC.COLUMBIA.EDU/ ~TEACHCOMM/STATES/ MAP.HTM 

THE NATIONAL CENTER FOR EDUCATION STATISTICS LISTS A VARIETY OF SCHOOL SUVEYS AT HTTP:// NCES.ED.GOv/SURVEYS/ DATASURV.HTM 

RESULTS OF THE MICHIGAN EDUCATIONAL ASSESSMENT PROGRAM (MEAP) AND HIGH SCHOOL PROFICIENCY TEST (HSPT) ARE AVAILABLE ONLINE FROM THE MICHIGAN DEPARTMENT OF EDUCATION AT HTTP:// www.MDE.STATE.MI.US/ REPORTS/MEAP 

Lynn Olson can be reached at lolson@epe.org 

3


ASSESSING THE E-RATE 

# Hookup hangups 

SULLIVAN WRITES: 

HERE'S SOME VITALS AS 

TO HOW TO GET STARTED 

ON YOUR OWN E-RATE 

STORY. THE WEB SITE FOR THE SCHOOLS AND 

LIBRARIES CORPORATION 

(WWW.SLCFUND.ORG) IS 

WELL ORGANIZED AND 

HAS LOTS OF 

BACKGROUND ON THE 

PROGRAM. IF YOU WANT 

TO GET RIGHT TO THE DATA, GO TO 

WWw.SLCFUND.ORG/ FORMS/ 

DOWNLOADSTATE.ASP 

THE ORIGINAL E-RATE STORY IS ACCESSIBLE ONLINE AT HTTP:// wwW.MSNBC.COM/NEWSI 169664.ASP 

By Bob Sullivan MSNBC 

Here's a story with two lessons. First, listen to your father. Second, even if you start your story with data, you can ultimately bail on it and still end up with a good story. 

And the good news is this story involves data on virtually every school district in the country - it would be easy to localize. 

My father is a computer teacher and tech- nology coordinator at two private schools. For several months, he consistently whined to me about a new requirement to fill out a "technology plan" for both schools. I figured he was just complaining about paper work. But one day he mentioned that he had been inundated with junk mail from PC makers, software makers and the like. Why? Well, those technology plans were being put up on the Web. The plans, he explained, included a wish list of all the equipment his schools hoped to purchase in the next few years to connect it to the Internet. So "service provid- ers" were making their pitch, and hard. 

OK, maybe I'm not yet smart enough to listen to my dad, but when someone says "those have been posted on the Web," my ears perk up. 

Before the weekend was up, I had down- loaded a database of computer equipment wish lists from 23,000 schools around the country. Then I worked backward to figure out what I was looking at. 

## Lopsided access 

I was looking at the real-life implementa- tion of one of the initiatives of the Telecom- munications Act of 1996. That law man- dated that the FCC set up a program essen- tially to re-route money from telecommuni- cations companies to schools - well, really telecommunications consumers to schools. The goal: universal access to the Internet for all schools. 

So the FCC created a nonprofit called the Schools and Libraries Corporation to admin- ister the program, now called the E-rate, or Education Rate. The SLC decided to dole out approximately $10 billion over 5 years in the form of discounts. The discounts up to 90 percent for the poorest schools - were determined by the percentage of students 

eligible for school lunch programs. The SLC had schools file wish lists (Form 470) and then settle on contracts with service providers (Form 471) after a bidding period. After all the 471s were gathered, the SLC sent letters confirming funding for the discounts. 

The database I downloaded represented Form 470s only - i.e., the wish lists, not the 

Already technologically hip areas were getting more equipment, while "unconnected" parts of the country weren't even participating. 

contracts. No dollar amounts were attached. But I was curious to see if there were any patterns in the data, if some areas of the country were taking advantage of the pro- gram more than others. 

When I sorted requests by state, it quickly became evident that states like Washington and New York applied for much more equip- ment than states like Arkansas or North Carolina. In other words, it looked like there might be a "rich get richer" story here - already technologically hip areas were getting more equipment, while "unconnected" parts of the country weren't even participating. 

## Applying for uncertain funding 

Here's where the real reporting came in. I wouldn't have had a story without the help of Dateline NBC's Andy Lehren, formerly of NICAR. Andy had experience working with the Department of Education's Common Core database. If my hypothesis were true, we'd be able to find poor schools that didn't apply for E-rate money. 

So Andy sorted schools in Arkansas, North Carolina, West Virginia and several other states that had more than 75 percent eligibil- ity for federal school lunch programs, then cross-referenced those schools with the SLC database. It didn't take long to find poor 

Continued on page seven 

4


A FEW GOOD CARs 

# Training gains ground 

## Karie Hollerbach 

Southeast Missouri State University Newsroom managing editors expect basic skills from new recruits with freshly minted journalism school degrees. At the top of the list usually is the ability not only to write but to write well. Working a beat is important, as is generating story ideas. And let's not forget interviewing technique, basic copy editing skills, and the motivation to get it first and get it right. 

But what pout computer-assisted report- ing skills? Are managing editors actively seeking recruits who can demonstrate that they have spent some time in front of a PC analyzing data and looking for a story? Are undergraduate journalism programs teach- gstudents the CAR skills they need to meet the expectations of managing editors? 

## Sprouting media 

CAR's impact on print journalism has been growing steadily since the early 1990s. A 1992 survey of 192 daily newspaper edi- tors found that more than half of the news- paper readers in the U.S received newspa- pers that were doing stories with computer- assisted record analysis, not only for special projects but for beat reporting as well. 

The top two reasons given by the editors for not using CAR were a lack of equipment and a lack of skilled personnel. One editor commented that his impression was that university journalism programs were behind the curve on this new trend of computer analysis. 

## Stunted schools 

A national survey of journalism schools, also completed in 1992-93, indicated that the majority of universities had no formal CAR instruction nor plans to add it. Of the 258 responding schools, 24 percent taught some form of record analysis while 13 per- cent offered formal instruction in online database searching. 

Betty Medsger's nationwide study on jour- nalism education for the Freedom Forum in 1996 found that computer skill education had become more widespread 87 percent of the journalism programs surveyed offered some type of it. Special courses had been 

created at 35 percent of the institutions sur- veyed, while 72 percent had included it in existing courses. However, only one-third of the journalism programs offering computer instruction of any kind required journalism majors to take those courses. 

## Supply and demand 

In an exploratory study I conducted in 1996-97, both university journalism/com- munication departments and newspaper managing editors were surveyed simulta- neously to determine the current supply and demand of CAR skills. 

Universities teaching CAR in their pro- grams and newspapers practicing CAR ranked differently - though the differences were not statistically significant the most important skills for journalism students to master: Internet use, database use, data acquisition, statistical analyses, and spreadsheet use. 

Nearly 85 percent of the universities said that they were teaching CAR. Of those not currently teaching CAR in their programs, 82 percent said they had future plans to do so. A lack of qualified faculty was the most frequent reason given for not teaching CAR. No one indicated that a lack of equipment posed a barrier to CAR's entrance into their program. 

Nearly 42 percent of the newspapers sur- veyed said that they were using CAR. Special projects and investigative reporting topped the list as the most frequent uses of CAR, but CAR as a part of daily news coverage was reported at 50 percent. Internet use was a frequently expected skill not only of new journalism school recruits but also of current staff members. A lack of funds and a a lack of qualified staff were the most frequently re- ported reason for not using CAR. Whether CAR is actively being taught or used, the skill sets valued by both university programs and newspapers are relatively the same. The real key is in teaching students how to apply those CAR skills. Progress is really made when journalism students can enter a newsroom prepared to conduct com- puter-assisted reporting at the touch of a button. 

Karie Hollerbach can be reached by e-mail at khollerbach@semovm.semo.edu 

AVAILABLE FROM THE IRE RESOURCE CENTER IS A PACKAGE OF SYLLABI AND ASSIGNMENTS FOR INVESTIGATIVE AND COMPUTER-ASSISTED REPORTING COURSES, DESIGNED BY ROSE CIOTTA, WENDELL COCHRAN, WILLIAM GAINES, BOB GREENE, BRANT HOUSTON, PENNY LOEB, JOHN ULLMANN, AND DEBBIE WOLFE. THE PACKAGE IS #558 IN THE RESOURCE CENTER. CALL (573) 882-3364 OR SEND AN EMAIL TO RESCNTR@IRE.ORG 

EXERCISES USING SPSS, A STATISTICAL SOFTWARE PACKAGE, ARE AVAILABLE FROM NICAR's DATABASE LIBRARY. CALL (573) 884- 7332 FOR MORE INFORMATION. 

5


REPORT CARDS REVISAL 

NICAR's DATABASE LIBRARY HAS RECENTLY ADDED THE FOLLOWING DATA SETS: 

THE HOME MORTGAGE DISCLOSURE ACT DATABASE FOR 1997, COLLECTED BY THE FEDERAL RESERVE BOARD TO TRACK HOME LOANS, HOME-IMPROVEMENT LOANS AND BANK- PURCHASED LOANS 

THE SMALL BUSINESS ADMINISTRATION'S 7A DATABASE OF LOANS APPROVED BY THE SBA UNDER ITS MAIN LENDING PROGRAM, KNOWN AS 7A 

ENDOWMENT FOR THE ARTS GRANTS PROGRAM DATABASE OF GRANTS TO INDIVIDUALS AND ORGANIZATIONS FROM 1987 THROUGH 1997 

THE IRS' TAX EXEMPT ORGANIZATION BUSINESS FILE, WHICH CONTAINS BASIC INFORMATION FROM ALL 990 FILINGS 

THE NATIONAL 

To ORDER OR HAVE YOUR QUESTIONS ANSWERED ABOUT ANY OF THESE DATABASES, CALL THE LIBRARY AT (573) 882- 0684. 

# Multi-layered ratings 

## By Jeff Porter Arkansas Democrat-Gazette 

Creating reams of school statistics is not difficult in itself. But the more challenging task was our mission to organize the reams to be able to help our readers make educated choices about schools. We also wanted to show intangible qualities of schools with interviews from educators, parents, students and others. 

So how did we do it? 

The Arkansas Democrat-Gazettepublished its second annual school statistics report on Aug. 23 in a 24-page tabloid ranking of 73 elementary, 15 junior high and 12 high schools in Pulaski County. 

## Quantifying performance 

The rankings used a broad set of catego- ries to quantify school performance in areas identified by educators, parents and federal courts. 

With most categories, the newspaper col- lected raw numbers then calculated rates - mostly per 100 students - to compare fairly schools of any size. The calculation was simple. For example, to calculate the high school dropout rate, we used the formula: (drop- outs/enrollment) X 100. We chose SPSS but could have easily used Excel or Visual FoxPro. The categories: 

Elementary schools: rates per 100 stu- dents for teachers, advanced-degree teachers, parent-group membership, volunteer hours and suspensions; a percentage showing either crowded or unused classroom space, calcu- lated by enrollment/capacity; average SAT scores for the fifth grade; racial disparity in those test scores (an issue a federal court is monitoring); and spending per student. 

Junior high schools: all the elementary figures except the test scores and racial dis- parity were calculated for seventh-graders; and rates per 100 students for dropouts and expulsions. 

High schools: the elementary and junior high school categories except the scores and disparity were for 10th-graders; ACT exami- nation averages; percentages of seniors taking the ACT; percentages of previous graduates who were forced to take remedial courses in state colleges and universities; percentages of seniors taking college preparation courses; 

and the total number of courses available. The Democrat-Gazette constructed tables with rankings - that is, which school is the "best" given this set of categories, all of which were valued equally. In 1997, we ranked with Excel. This year, we used SPSS, a statistical software package that is much handier for this purpose. 

We identified schools that beat the odds and did significantly better in the test scores than predicted. Then we wrote about how those schools are making a difference. 

We had SPSS rank each category in re- verse order. That, in effect, created point scores for each school. For example, the worst elementary school in the teacher-student ra- tio category was ranked "1." The best school, then, would have a score of 73, or the total number of elementary schools. 

Then we had SPSS create an average score using all of the scoring columns. The top average score became our top-ranked school. We showed the average scores, but instead of using unfamiliar groupings such as quartiles or quintiles, we assigned letter grades for schools. Those letter grades helped readers understand that average scores were quite close for many schools. 

But was it fair? Not if that were all we did. Like last year, and even more in-depth this year, the newspaper showed readers how to zero-in on categories and to find schools doing well in them. Graphics portrayed how schools fared in each category. Readers can track categories they deemed most important and judge how particular schools are doing. 

## Chasing intangibles 

We wrote serious stories about some of the higher-ranked schools and showed how they have been successful. Those stories aren't top-heavy with numbers but rather empha- size interviews. We did stories about some 

Continued on page seven 

6


# From page four: Wishful listing 

schools not in the SLC database. 

Spending several weeks calling those schools gave me a great, real-life picture of how difficult the E-rate application process was - and why some schools didn't apply. More important, found an even larger story. Every school that applied for E-rate money was stuck in limbo: E-rate funding was ex- pected in late winter or early spring. Schools that had applied either went ahead with their purchases by spending their own money and hoping E-rate funding would come through, or, more likely, just sat and waited. 

## Posted warnings 

There's plenty of caveats to using this data in your story, though. Most important, not every application for service is included in the now 24,000 or so applications you'll see. Only requests for "new service" are included. Schools were allowed to apply for discounts for existing service provider contracts, but they are not included. Schools were also allowed to apply for discounts on plain old phone service, but those applications are not included, either. Finally, some schools applied as cooperatives. You should also know that schools were able to enter their own applications on the Web, making the data pretty dirty. I had to remove hundreds of duplicate records. All that said, however, you'll find down- loading the data and looking at schools in your area to be a great starting point for a story on how well your schools did with their 

E-rate applications. As an added bonus, every application comes with a contact name and phone number (usually the district's technol- ogy coordinator), so it's an invaluable re- source. 

Also note that the database contains only some of the raw numbers culled from each school's application. The applications them- selves can also be retrieved (one at a time) from the SLC Web site. If you're going in- depth on a few schools, you'll want to see the actual application, which contains lots of additional commentary. The SLC folks agreed with me that, be- cause of the cooperative factor, the most accurate way to sort the data was to examine it state by state. It is interesting to see which states applied for more new services than others. Interesting, but not as conclusive as the interviews to which the data led us. In the end, after considering to omit ref- erence to the data, we only included one chart - a ranking of states that asked for the most new video hookup services per student. We gave it no more credibility than any other source in the story. One more caveat found explaining the SLC and the E-rate process to be pretty tricky. Prepare your editor for some tortured paragraphs if you're really interested in fully explaining how the funding mechanism works. Bob Sullivan can be reached by e-mail at Bob.Sullivan@MSNBC.com or by phone at (425) 936-7751 

SULLIVAN ALSO NOTES: 

As OF THIS WRITING SCHOOLS ARE STILL WAITING. THE LATEST WORD FROM THE SLC IS THAT FUNDING WILL ARRIVE SOMETIME IN THE FALL. 

## Filing flurry 

From page six: 

And we went even beyond that, espe- cially with the elementary schools. Using fifth grade average SAT scores and the percentage of children taking part in the free and reduced lunch program, we cre- ated a regression analysis showing how the two factors are related. We identified schools that beat the odds and did signifi- cantly better in the test scores than pre- 

schools, though not ranking highest, that ranked well in specific categories. We also looked at schools that fell in the rankings this year to learn why. 

IT'S NOT TOO EARLY TO THINK ABOUT IRE/ NICAR's 1999 NATIONAL CONFERENCES. NICAR's NATIONAL CONFERENCE WILL BE HELD MARCH II- 14 IN BOSTON. IRE's NATIONAL CONFERENCE WILL BE HELD JUNE 3-6 IN KANSAS CITY. CHECK OUT IRE's WEB SITE AT www.IRE.ORG/RESOURCES/ 

dicted. Then we wrote about how those schools are making a difference. For our purposes, we looked at one other scatterplot. Pleasingly, the plot showed that race had no bearing on schools' average scores. Most newspapers avoid ranking and grad- ingschools. We rank and grade them because we are confident of our statistics and want to help our readers make sense of the data instead of merely presenting a jumble of numbers that lead to no conclusions. jeff Porter can be reached by e-mail at jporter@ardemgaz.com 

CONFERENCES/INDEX.HTML FOR MORE INFORMATION. 

THE PACKAGE IS ALSO AVAILABLE ONLINE AT www.ARDEMGAZ.COM UNDER PREVIOUS FEATURES. 

7


# Unexpected results 

From page one: 

To STEER YOUR CAR PROJECTS IN THE RIGHT DIRECTION, ORDER "COMPUTER-ASSISTED REPORTING: A PRACTICAL GUIDE" BY BRANT HOUSTON. IT CAN BE ORDERED FROM NICAR AND INVESTIGATIVE REPORTERS AND EDITORS FOR $26 FOR IRE MEMBERS OR $30 FOR NON-MEMBERS PLUS SHIPPING. CALL (573) 882-2042. 

FOR A LISTING OF OTHER 

TITLES AVAILABLE CONCERNING COMPUTER- ASSISTED AND 

INVESTIGATIVE REPORTING TECHNIQUES, VISIT OUR 

WEB SITE AT WWW.IRE.ORG/ PUBLICATIONS/ BOOKSTORE 

SUBSCRIBE ONLINE: 

You CAN NOW SUBSCRIBE 

TO UPLINK ONLINE. POINT YOUR BROWSER TO www.IRE.ORG/RESOURCESI NICAR/UPLINK 

our readers and viewers how much better schools in well-to-do neighborhoods are than those in poorer communities. In talking with university researchers who study what differ- entiates "good" schools from "bad" ones, however, we found out they believe many inner-city schools are actually accomplishing astounding results given the poverty-related difficulties they have to deal with. 

## Against the odds 

To demonstrate that point, we decided to take the best available poverty data for each school-the percentage its students receiving free lunches - and analyze their test scores compared to their poverty level. (One caution: using free lunch as a poverty indicator works fine at the elementary level. But once children reach junior high school, many refuse to take part in the program because of the embarrass- ment of being identified as "poor." It's not a good substitute for actual income figures.) 

Using SPSS, we ran a regression analysis that, in short, showed us how each school's test scores compared to average scores for schools with the same poverty rate. The result: In our Albany backyard, we had one of the best elementary schools in the state, al- though we never would have known it based on its raw test scores. 

School20' raw scores, in fact, were slightly below average. But with 96 percent of its students participating in the free lunch pro- gram, it should have had test scores that scraped the bottom. In fact, School 20 ranked among the top 70 of nearly 1,900 public elementary schools in New York. Sitting less than a mile away, in the adjoining attendance district, was Albany's Philip Schuyler El- ementary School. Schuyler, with a slightly lower free lunch rate, had even lower test scores, ranking among the bottom 20 per- cent of schools in our regression analysis. 

Poor vs. poor 

We decided to take an in-depth look at the two schools, which were dealing kids from essentially the same demographic groups, in order to determine what made one so much more successful than the other. But first, we had to make sure that, in fact, the student bodies were very similar in makeup. We did that by plugging the attendance 

boundaries for each school into MapInfo, then adding county census and welfare data. We interviewed academics about what to look for in the schools, factors like teacher involvement in educational decision-mak- ing, good library resources, or strong leader- ship from the school principal. The next step getting into the schools - was surprisingly easy. The district superintendent and both principals gave a reporter and photographer free rein to roam the halls and classrooms. What we found helped us dispel the notion that inner-city schools are by definition worse than their suburban counterparts. In fact, our regression analysis found that several suburban schools scored far lower than would be ex- pected given their low poverty rates. The regression showed a 75-percent cor- relation between poverty rate and test scores, which means statistically that poverty "ac- counts" for three-fourths of how kids do on tests. As a newspaper based in the state capi- tal, we didn't take long deciding, that we ought to take a look at what the state govern- ment was doing about providing extra re- sources to poorer districts, since poverty is a significant determinant of performance. 

## Misapplied aid 

Like most states, New York funds its schools primarily through local property taxes. But it also hands out more than $10 billion annually in school In theory, more money is supposed to go to school districts with the least resources per student. In reality, power- ful legislators from suburban districts have made sure their schools get sizable chunks. We analyzed state Department of Educa- tion data concerning aid compared with pov- erty rates among school-age children in the districts and found that the state's aid system was completely out of whack. For example, the city of Albany has the 26th-highest child poverty rate in the state but ranks 543rd in state aid. Buffalo, with the highest poverty rate and the lowest median income, is 186th in state aid. With a citizens' lawsuit already challenging the state aid formula, advocates for restructuring it were planning to use the same type of analysis as we did to support their case. 

Harvy Lipman can be reached at hlipman@timesunion.com 

8


TECH TIP 

# On being and nothingness 

By Richard Mullins NICAR/Missouri School of Journalism 

If I were clever, I would title this Tech Tip "On being and nothingness." But I'm not and I did, so there's an existential di- lemma for you. It's about nulls, an explicit, unambigu- ous and logically tricky way of talking about nothing. Knowing about nulls is significant for at least two kinds of queries: summary queries using the count ( ) aggregate function and queries filtering for empty character fields. If you use FoxPro versions 2.x, then you may never have heard of nulls. Even if you've used the last of the old FoxPro, version 2.6, you might not have noticed the idea of nulls. Nothing lost, however: the implementation of nulls in 2.6 was incomplete and not worth bothering with. If you made the switch from old FoxPro to new Visual FoxPro, or to Access, you might have bumped into nulls in the docu- mentation - or been assaulted by one in an error message. Or you might have been using bad words in front of your 11-month-old computer because you kept doing an Access query for blank occupations, the query kept saying there weren't any, but you knew there were plenty. You were in the twilight edge of the null zone and things are different there. Here is an explanation from the Visual FoxPro documentation: Visual FoxPro provides support for null val- ues. This support simplifies the task of repre- senting unknown data and makes it easier to work with Microsoft Access or SQL databases that may contain null values. 

## Standardizing the unknown 

The explanation is intended to be gentle, but it borders on the euphemistic. I would say that nulls standardize the representation of unknown data. And, obviously, software is easier - and gives the user fewer problems when it conforms to standards. 

Also from the Visual FoxPro documenta- tion, these definitions: 

Null values are: 
Equal to the absence of any value. Different than zero, the empty string ("6" or blank. 
Sorted ahead of other data. Propagated in calculations and most func- tions. 
Null values affect the behavior of com- mands and functions, logical expressions and parameters. 
Null value: Having no explicitly assigned value. NULL is not equivalent to zero or blank. A value of NULL is not considered to be greater than, less than, different than, or equivalent to any other value, including another value of NULL. 

Any datatype can contain a null. Nulls should be used to indicate things like miss- ing data or unknown value. It does not stand for a quantity with a meaning. For example, an age column with a null means that the age is unknown, not that the person is unborn or dead. Same thing for a column indicating sex or gender: null means unknown, not a new biological condition. 

## Nullified values 

Here is how nulls affect summary queries using the count ( ) function. Using count (ColumnName) will only include rows where that particular column has some non-null value in it. Using count (*) will count all rows. FoxPro 2.6, for example, allows both methods because this is standard SQL. It just treats them identically and gives the same answer, which is not standard SQL. The other item to explain from the documentation is this statement: "Nulls propagate through calculations and most functions." If a single column or variable containing a null is anywhere inside a nest of calculations or functions, then the an- swer is null. This fact can be especially tricky if you are looking at logical or true/ false columns. Null is neither true nor false. Without knowing this, you could misinterpret your results. 

Richard Mullins can be reached by e-mail at richard@nicar.org. 

IF YOU WOULD LIKE TO SEE A PARTICLUAR PROBLEM ADDRESSED IN THIS COLUMN OR IF YOU WOULD LIKE TO CONTRIBUTE YOUR OWN SOLUTION TO ONE, PLEASE SEND AN E-MAIL TO BRENT JOHNSON AT BJOHNSON@NICAR.ORG 

THE OCTOBER 1998 ISSUE OF UPLINK WILL FOCUS ON THE USE OF COMPUTER-ASSISTED REPORTING IN ENVIRONMENTAL STORIES. IF YOUR ORGANIZATION COMPLETED AN APPLICABLE STORY AND YOU WOULD LIKE TO SHARE YOUR INSIGHTS ON SUCCESSFULLY DOING ONE, PLEASE SEND AN E- MAIL TO BRENT JOHNSON AT BJOHNSON@NICAR.ORG. 

OTHER UPCOMING ISSUES WILL FOCUS ON THE CENSUS, CAMPAIGN FINANCE, CRIME, TRANSPORTATION, INTERNATIONAL CAR AND CAR AT SMALL NEWS ORGANIZATIONS. IF YOU WOULD LIKE TO SUBMIT AN ARTICLE OR COLUMN TO ONE OF THESE ISSUES, PLEASE CONTACT BRENT JOHNSON. 

9


HANDOUT OF THE MONTH 

OTHER EDUCATION HANDOUTS AVAILABLE FROM THE IRE RESOURCE CENTER INCLUDE: 

ROSEMARY ARMAO'S "12 STEPS TO STERLING SCHOOL COVERAGE" (#235), WITH TIPS ON FRAMING STORIES, FOLLOWING THE MONEY, THE STUDENTS AND THE PROMISES 
JIM HEANEY'S "How TO SIZE UP YOUR SCHOOL DISTRICT" (#513) WITH 
TIPS ON ASSESSING 
ACADEMIC ACHIEVEMENT, 
INNOVATION AND 
CURRICULUM, BUILDING CONDITIONS, AND SCHOOL SAFETY 
BETH SHUSTER'S TIPS FOR EDUCATION REPORTERS ON 
DOCUMENTS THAT COULD 
YIELD GOOD 
INVESTIGATIVE STORIES (#106) 
ALSO ASK FOR OTHER NAPOLITANO HANDOUTS: 
614 - USING CAR TO COVER HOUSING (WITH PENNY LOEB AND MIKE HIMOWITZ) 
425 - CAR STORIES 
NEWS ORGANIZATIONS OF ALL SIZES 
THAT COULD BE DONE AT 

## Carol Napolitano 

# Analyzing test scores 

The Omaha World-Herald Before you ask a school district or state for test score data, think about how you may want to use it. Do your homework. Take the time to look at what other news organizations have done with similar data. Solicit ideas from reporters and editors in your own news- room and ask them what they'd like to see written. If you have a good relationship with any teachers or members of the local PTA, ask them the same question. Keep things focused. There are so many potentially good stories in these data. Without focus, you risk getting lost, getting frustrated, and produc- ing a lot of mediocre stories instead of a few really good ones. 

## Demanding details 

Try to get student-level data. Some dis- tricts keep only minimal information; others gather demographic and socioeconomic in- formation on students and their families. Get as many years of data as you can. Analysis of test scores for a single year is pointless if the focus of your stories is performance. Try to get three to five years at a minimum. 

Following is a sample wish list for stu- dent-level data. If you can get only school- level data, try to get aggregates like gender and race percentages. 

Student ID (Student names are confi- dential, but sometimes the district or state will generate an ID number for each student that you can use. This will allow you to do longitudinal analysis.) 

Grade level, teacher, school attended 
Gender, race 
Grade point average 
Parent education level 

Family income information. Participa- tion in free or reduced lunch programs is the most commonly used indicator of poverty or low income. Free lunch participation tends to dwindle as students get older and it be- comes more of a social stigma. So, if the district keeps a more stable indicator, like parent's income range, get that, too, 

into small geographic areas. Even if there is no desegregation plan, the district may di- vide its area into smaller sections. With any luck, you can match these areas to census and property information to get a feel for the demographics of a student's home environ- ment: Do they come from an area with a lot 

Bottom line - know the difference between a percentage and a percentile; know the difference between NCE, scale and percentile scores; and have a good understanding of statistics. 

Student ZIP codes or a more specific geographic level, like nodes or census subdis- tricts. (Student addresses usually are confi- dential.) If your district has a desegregation plan, chances are it has divided the district 

of rental units or single-parent families? An area where high school or college graduation rates are very low or very high? An area where the average cost of a home is six figures? 

Test scores for all subjects tested, plus total battery scores. Ask for NCE scores, as well as percentiles. You can't do math with percentiles. 
Mobility figures: How often has the student moved within the district? Is there an indicator denoting when the student entered the district from another district? 
Parent participation numbers. Some schools keep data on what percentage of parents participate in the PTA, school events, report meetings, or teacher conferences. 

## Statistical differences 

School districts will vary widely in terms of the statistical expertise they have on staff. But even the least sophisticated school re- searchers may assume they know more than you do and that you will mess things up. They may be right. You may mess it up if you don't know what you are doing. Bottom the difference between a percent- age and a percentile; know the difference between NCE, scale and percentile scores; Continued on page eleven 

10


# From page ten: Scool portraiture 

and have a good understanding of statistics. Do you know what this means and how to use it? 

y = B + + E 

If you don't know what that formula is or how to use it, take a course on linear regres- sion or get yourself a consultant. While you can spend big bucks on consultants, there are less expensive alternatives: another journalist who has done this type of work, someone at your own news organization in quality con- trol or marketing who has a statistics back- ground, or a professor at a local college will- ing to work for a nominal fee or for free. 

## Perils and pitfalls 

Test score data is full of pitfalls; some may be unique to your data. A thorough knowl- edge of the school district will help you spot any problems. Things you might encounter: 

Universal lunch schools. These are schools where the percentage of low-income students is SO high that all students are eli- gible for free/reduced lunch whether their family income qualifies them or not. This will affect your use of free/reduced lunch as an income indicator. 
Grade bias. In some districts, certain grade levels traditionally do better on stan- dardized tests than others. In Omaha, it was the 2nd grade. Because of the city's desegre- gation plan, this biased the results for schools that had only 2nd grade test-takers in their school. If this bias exists, you can choose to exclude these schools or disclose this problem to the readers. 
Apples-and-oranges demographic com- parison. When accumulating demographics to accompany the test score data, make sure you're comparing the same population. For example, if the standardized test is only given to 2nd, 4th and 6th graders, use demograph- ics for the test-taking population only. 
Means versus medians. If your dataset is small or the scores are not normally distrib- uted, consider using median scores for your analysis instead of mean scores. The more you boil down your dataset (schools, grade levels or even individual classrooms), the more you should consider using medians. 
Mobility. If you are using mobility as a 

variable in your regression model, make sure to find out how it is defined. Some schools count only students entering a school or district after the last registration day; some count only students leaving; and some count both types of movement. 

Inflating prediction. toverload your analytic model with predictor variables. If you dump too many variables into a regres- sion model, you will artificially inflate the results. Watch for variables that correlate highly with each other. Putting them both into the model also can cause problems. 

## Unavoidably incomplete 

Remember to acknowledge to readers the limitations of your analysis. You can't create a statistical model that explains all the differ- ences in test scores. 

Regression is better at analyzing groups than individual students. You'll find this out yourself if you build a model and apply it to individual student scores and then to aggre- gate school scores. The model will explain significantly more difference in school level scores than individual ones. 

A common criticism of test score analysis is that it "makes excuses" or "sets the bar lower" for poor or minority students. This perspective often comes from people believ- ing that your analysis is predicting how stu- dents are going to score on future tests be- cause of their socioeconomic status. While it is true that regression analysis is used for prediction, the modelbased on historic performanceletters of these students or schools (providing you have ample years of data in your analysis). In your stories, you may also consider avoiding words like 'ex- pected, which for some may connote that you are setting different levels of expectations for different students or groups. Explain how you did your analysis, but expect that you'll never satisfy all your read- ers. You'll hear from different people if you keep your explanation too simple or vague than if you make the explanation too detailed or complex. Consider providing a moderate amount of detail in the stories and then publishing a more detailed appendix that people can order. 

To SEARCH THE COLLECTION OF CONFERENCE HANDOUTS AVAILABLE FROM THE IRE 

Carol Napolitano can be reached by e-mail Carolnap@owh.com 

RESOURCE CENTER, VISIT OUR WEB SITE AT 

www.IRE.ORG/RESOURCES/ CENTER/ 

HANDSEARCH.HTML 

HANDOUTS ARE SORTED BY SUBJECT, YEAR AND LOCATION. 

To SEARCH THE LIBRARY OF MORE THAN 12,000 INVESTIGATIVE STORIES AVAILABLE, VISIT www.IRE.ORG/RESOURCES/ CENTER/SEARCH.HTML 

THE RESOURCE CENTER CAN BE REACHED AT (573) 882-3364 OR BY EMAIL AT RESCNTR@IRE.ORG 

11


STATS FROM THE ROAD 

# Sampling large groups 

UPCOMING BOOT CAMPS: 

OCTOBER 22-25, 1998 POWER BOOT CAMP IN COLUMBIA, Mo. (A BASIC BOOT CAMP SQUEEZING SIX DAYS OF TRAINING INTO FOUR.) 

JANUARY 3-8, 1999 - BASIC BOOT CAMP IN COLUMBIA, Mo. 

MAY 16-21, 1999 - BASIC BOOT CAMP IN COLUMBIA, Mo. 

FOR A COMPLETE LISTING OF UPCOMING IRE AND NICAR EVENTS, 

INCLUDING BOOT CAMPS, ON-THE-ROAD TRAINING, SEMINARS AND REGIONAL CONFERENCES, VISIT OUR WEB SITE AT 

WWW.IRE.ORG/ CALENDAR.HTML 

## By Sarah Cohen NICAR 

This is the second installment of a two-part Last month, this column advised you how to decide whether testing a small set of data might help focus your project, to provide a game plan for gathering documents and to hone your data analysis. That's all well and good. But how do you sample a large group? 

First decide the purpose of your sample. That will often drive you toward one of the common sampling methods, though more complex methods exist. 

There's really a ladder in sampling tech- niques. At the bottom, researchers simply pick some cases, sometimes for a reason. Then they put a fancy word on the technique- "judgmen- tal sample." For purists, though, only a true random sample, which carries the imprimatur of science, will do. 

But random samples often won't do what you want, at least not with huge samples that might be beyond your means. In the middle, samples are based on the concept of random numbers but are "assisted" or "stratified" to give a relatively large set of particular instances you know you need. 

## Exploratory tools 

Let's start at the bottom with the "judgmen- tal sample," or a sample of convenience. Here, you pick out documents or records you know interest you and examine them in depth. An example is the most recent 50 entries into a database compared with the original docu- ments that generated the records. Looking at what happened lately can give you a big hint at what's to come. 

These kinds of seat-of-the-pants tests are particularly useful as exploratory tools to deter- minewhether to go further in your project. You might want to treat them the same way re- searchers treat "content analysis" the science of studying documents for trends. It's the clos- est analogy in social science for much of what we do in the newsroom. 

Researchers will sometimes check whether data entry clerks categorize items the same way. This step is particularly important when asking for help in collecting as well as entering data. Using this kind of sampling would have helped one newspaper that hired clerks to collect and 

type demographic information on college coaches. Simple questions about the coaches, such as years of experience, were interpreted differently. One clerk counted junior college. Another counted high school. A third counted only assistantships at major universities. 

When you care about specific instances for your story - people who drive red cars, people who live in your county, or airplanes that land at your airport - judgmental samples are also useful. But if you stop there, you'll miss your story's crucial "compared to what" statement. You may know what happens locally, but you won't have context of what happens elsewhere. 

## Planning randomness 

At the other end of the spectrum is the pure random sample, usually reserved for stories in which you plan to state your findings without ever studying the "population." 

The major criteriafor random sample: The sample must be selected from a list of every possible person, document or company you' studying. In most polls, this is virtually impossible. Researchers use samples of every known telephone number, registered voter, or company paying unemployment insurance. 

Every person or case has an equal chance of selection. No one is excluded. 
Picking one case has no influence on picking any other. 

Getting a random sample is easy. First, make sure your data contain unique record identifiers. In Access, you'll want to create an "AutoNumber" field. If you already have one, make sure you haven't deleted any records so you can use it as a record number. Note the number of records in your database. 

Then go into Excel and create random numbers. (These aren't exactly random- they won't repeat your numbers for quite some time.) Your function will look something like this: =RANDBETWEEN(1,2000000) This picks a random number between 1 and 2 million, which you'd use if you had exactly 2 million records in your original database. 

Copy to as many rows as you want for your sample. Unless you want to look at sub-groups, in which you will need more records, most samples are about 350 records. Then copy and paste this list into a new Access table. You may 

Continued on page fifteen 

12


FIRST VENTURES 

# Valley of the dollars 

By Hugo Martin Los Angeles Times 

To be honest, math has always been a four-letter word for me. If it were up to me, the Geneva Convention's list of cruel and unusual punishments would include the task of figuring out percentages. So I was de- lighted to learn during my first CAR lesson that a computer can be used to sort reams of data, add rows and rows of figures, and oh joy - figure out percentages. My first thought upon taking CAR class was to use the computer to spare me the agony of calculating from those mind-numb- ingly long campaign finance reports that I was forced to analyze as the political reporter for the San Fernando Valley edition of the Los Angeles Times. With some tips from Sarah Cohen, NICAR's on-the-road trainer, I more than 500 campaign contributions made to the top two candidates for a hotly contested state Senate race in the Valley. 

## Seeking sources 

I started the project with two main goals: Find out where, geographically speaking, the contributions came from and what occupa- tions donated the most money. Then I could compare the two candidates: former assem- blyman Richard Katz and city councilman Richard Alarcon. 

My first challenge was converting the data from hard copies of campaign finance reports to a database I could manipulate. Once I downloaded the campaign data into Access, I found lots of missing data, in particular the occupations and addresses of some contribu- tors. To fill the holes, I called the campaign offices for each candidate and entered the information manually. 

The campaign finance data of the Times library included a column that contained the ZIP code for every contributor to the two candidates. I linked the ZIP code listing in the database to a table of district ZIP codes that I created. That showed me how many contributions came from within the district. 

I also created separate tables with the ZIP codes for the San Fernando Valley, Los An- geles and Sacramento, home of many of the 

state's lobbying groups and labor unions. I then sorted the contributions by those geo- graphic areas. 

## Limited local loot 

The results were surprising. District resi- dents and businesses contributed only eight percent of the money raised by each candi- date. The vast bulk of contributions came 

The results were surprising. District residents and businesses contributed only eight percent of the money raised by each candidate. 

from addresses spread throughout southern and northern California, sizableamount from Sacramento. 

To sort the contributors by occupa- tion, I created a new column in the cam- paign database and plugged in generic descriptions for each contributor so that they could be sorted into multiple general categories, such as transportation firms, lawyers, real estate businesses, labor unions and so on. 

then sorted to add the amounts of money generated from each occupation. This did otreveal many surprises. Much of the money came from expected sources. 

## Excel-baked pie 

The real magic came when I used the Excel program to make pie charts. With a few simple mouse clicks, a chart illustrated how much money came from within and without the district. Another chart showed how much came from lawyers, unions and other groups. This impressed my editors because the numbers were easier to visualize and present to readers. 

But the best part was that Excel automati- cally figured out the percentages for each slice of the pie. 

Hugo Martin can be reached by e-mail at Hugo.Martin@latimes.com or by phone at (213) 237-7086 

JOBS: 

FOR RECENT JOB POSTINGS TO THE IRE WEB SITE, INCLUDING A POSITION WITH THE JOURNAL GAZETTE IN FORT WAYNE, INDIANA, POINT YOUR BROWSER TO WWW.IRE.ORG/JOBS 

ONLINE CAR PROJECTS: To VIEW A LISTING OF LINKS OF RECENT COMPUTER-ASSISTED REPORTING STORIES POSTED ON THE WEB, POINT YOUR INTERNET BROWSER TO WWW.IRE.ORG/ RESOURCES/CONFERENCES/ TRAINING/ CARPROJECTS.HTML 

THE SITE INCLUDES A DESCRIPTION OF THE STORIES AS WELL AS LINKS TO IRE AWARD WINNERS. IF YOU WOULD LIKE TO SEE A STORY ADDED TO THE LIST OF LINKS, SEND JACK DOLAN AN E-MAIL AT JACK@NICAR.ORG 

13


ON THE INTERNET 

# Unearthing experts 

CHECK OUT THE LINKS TO EDUCATION-RELATED SITES ON THE BEAT PAGE OF REPORTER.ORG'S WEB SITE (www.REPORTER.ORG). THE BEAT PAGE ALSO INCLUDES TOPICS SUCH AS HEALTH CARE, THE ENVIRONMENT, TRANSPORTATION, DISASTERS, BUSINESS, POLITICS AND CRIME. 

ALSO CHECK OUT THESE HANDOUTS AVAILABLE FROM THE IRE RESOURCE CENTER: 

NORA PAUL'S "CAR ON THE EDUCATION BEAT, ONLINE SOURCES" (#335) 
"ELECTRONIC SOURCES OF EDUCATION INFORMATION" (#391) 

SEE THE SOURCES MENTIONED IN THIS COLUMN ON BENNETT'S WEB PAGE, "SOURCES AND EXPERTS" (HTTP:// SUNSITE.UNC.EDU/ SLANEWS/INTERNET/ EXPERTS.HTML) 

## By Kitty Bennett St. Petersburg Times 

The following is excerpted from a handout provided at the June 1998 IRE National Con- ference in New Orleans. 

Check out experts directories on the Web. You know those "Guide to the Faculty Experts at Wahoo University" books your local institutions of higher learning or favor- ite think tanks send out annually? Chances are good that they're also available on the Web. These directories typically offer ex- perts' credentials in excruciating detail, as well as contact information. Who needs big collections of paper directories? 

Online directories are often featured prominently on an organization's Web site. Sometimes they're grouped together with other information like press releases. 

Repositories of experts come in many different forms. Think creatively: When you're looking for experts, Amazon.com isn't a place to buy books, it's a database of over a million experts. Same goes for the Library of Congress. The New York Times Book Review is not only a great place to check out an author's credibility but also a good place to search for experts. It's free and contains over 50,000 reviews going back to 1980. 

Other databases of experts masquerading as something else: AskEric (www.askeric.org), the Educational Resources Information Cen- ter, and the National Library of Medicine (http://www.nlm.nih.govldatabases/ freemedl.himl), a database of nine million ref- erences to articles in 4,000 medical journals. 

Look for experts in newsgroup and listserv postings, but be cautious. These are wild and woolly places to be searching for experts and can become black holes into which you valuable time. If you do find someone you think is an expert, it can be difficult to gauge his credibility. 

An intelligent, targeted search can turn up somegems. To foster productive searching in DejaNews (www.dejanews.com), the premier newsgroup search engine that contains 100 million postings going back to March 1995, go to the Search Language Help page (www.dejanews. com/help/help_lang.shtm), print it and keep it next to you. Always use the Power Search option. 

There are far fewer options for searching electronic mailing lists, but a good first step is Reference. COM (www.reference.com), an archives of three months' worth of postings to 8,000 mailing lists (of an estimated 100,000+). You can store queries and run them automatically every day if you want. 

Try the Directory of Scholarly and Profes- sional E-Conferences (www.n2h2.com/ KOVACS/). It's a good source f4,000 mostly high-quality mailing lists and newsgroups on topics of interest to scholars and profession- als, divided into more than 50 subjects. 

Use traditional search engines effi- ciently. AltaVista (www.altavista.digital.com supports proximity searching, truncation and all sorts of sophisticated search capabilities that makes it ideal for finding experts. It can limit searching to URLs with certain words in them or to particular domains, but only if you click on "Advanced" and your search into the "Boolean expression" box. You can do somewhat complicated - but effective - searches like this one: (expert or author* or research* or professor) near astron* and (url:mit or url:princeton or url:stanford). 

You can' tignore HotBot (www.hotbot.com) because of the huge size of its database. 

Beaucoup! (www.beaucoup.com) has more than 1,000 engines, directories and indices listed, divided into 20 categories. Search.com (www.search.com) gives you 100 different ways to search the Web, di- vided into 14 different categories. The Mining Co. (www.miningco.com) is a search engine but also has 500 interest areas, moderated by expert guides, on everything from the aviation industry to zines. Check your expert's credibility. If you found your expert at a reputable university or think tank, you're on pretty firm ground. Someone else checked out his credentials before he got there. 

Find out who else has quoted your expert because of her expertise. Run her name through a commercial online service such as Lexis/Nexis. Many reputable publications have free searchable archives. For links to free archives, see News Hunt www.newsbount.com) Run your expert's name through several search engines. Try Northern Light 

Continued on page fifteen 

14


From page twelve: 

# Random roundup 

need to change the to Integer." Join the two tables on your utoNumber field, which only keeps records listed on both tables. 

## Implicitly stratified 

The dirty little secret of sampling is that hardly anyone - neither the major statistical agencies nor the pollsters - conducts pure random samples. In fact, some statistics books say that only a "probability-based" sample, not a random one, is needed to make statements about the larger group. 

Statisticians, then, often do something close to - but not quite - random sampling. It's often called "list-assisted" or "implicitly strati- fied" sampling. Instead of choosing a list of purely random numbers, these methods take a random starting point, then choose every sub- sequent 10th or 100th (or some other number) record. It's guarantees the sample has the mix you care about: demographics, time, or even data entry clerks. 

There are three steps to these samples: Sort by an important element, like date, keypunch operator's initials, or ZIP code. Determine the "sampling interval," or the number of records between each record se- lected, to give you the sample size you want. Divide the number of records by the sample size. For instance, a sample of 350 records out of 2 million records would have a sampling interval of 5,714. 

Figure out which records to select. You want what's called a "random start." Select a random decimal between 0 and 1, then multi- ply by the sampling interval. If your sampling interval is 5,714 and your random decimal is 

.35, then you'll start with the 2,000th record, followed by the 7,714th, and so on. Again, it's easiest to create the list of num- bers in Excel, then paste and join it in Access. 

## Explicitly stratified 

Other sampling variations include what statisticians call "explicitly stratified" samples, used when comparing one group to another or when you have evidence that one group would beunder-represented in more random sample. The key to this method is predicting into which group an item or a person falls. 

Say, for instance, you want to compare recidivists with non-recidivists, who are rare. If you can identify which cases fall into the two groups in advance, you can use either random method to select an equal number of cases from each group. Or you can sub-sample from the larger group, keeping only one of four who returned to jail. But here you cannot discuss all prisoners-you're limited to discussing differ- ences between the groups. 

No matter which method you use, select enough cases for your story. A sample of 385 or so will let you predict about the larger popula- tion within five percentage points of your estimate. Often, we want much more preci- sion. You have to raise the sample quite a bit to lower this range to one or two percentage points. Look in a statistics book if you need to find a sample size. But don't start down this road if you aren't willing to look at enough cases or talk with enough people to make your story's point. Sarah Cohen can be reached by e-mail at sarah@nicar.org. 

From page fourteen: 

NICAR's DATABASE LIBRARY CAN CONVERT DATA FROM ALL TYPES OF GOVERNMENT SYSTEMS. THE STAFF CAN TAKE NINE- TRACK TAPES, 4MM DAT TAPES, 3480 CARTRIDGES, PRINT IMAGE FILES OR TRI/ TR2 TAPES, AND PUT THEM ONTO CD-ROM IN THE DATABASE FORMAT OF YOUR CHOICE. NICAR STAFF CLEANS AND CONVERTS THE DATA, AND PERFORMS 

testimony-for-hire industry. That doesn't mean that they aren't experts, but you really want to check out their reputations. James Derk in his excellent story on experts ("Char- latans or Authorities?," Editor and Publisher, June 14, 1997) quotes ProfNet's Dan Forbush as saying, "Ultimately it's up to the journal- ists to decide the qualifications of the expert." Kitty Bennett can be reached by e-mail at bennett@sptimes.com. 

INTEGRITY CHECKS. PRICES ARE BASED ON THE SIZE OF YOUR NEWS 

Credibility checks 

(www.nlsearch.com), which hasa "Special Col- lection" of 3,400 high quality publications. Don't forget to check you expert out in DejaNews for indications of her expertise and/or psychoses. For all you know, she may be a frequent poster in alt. binaries .pictures. tasteless or alt.impeach.clinton. When using experts found in expert wit- ness directories, like ExpertPages.com, re- member that these people are part of the 

PLEASE CALL THE DATA- BASE LIBRARY AT 573-882- 0684 FOR MORE INFORMATION. 

FOR MORE INFORMATION ON THE CONTENTS OF THE DATABASES AND THEIR COSTS, CALL THE LIBRARY AT (573) 884- 7332. 

ORGANIZATION. 

A DOWNLOADABLE ORDER FORM IS AVAILABLE AT www.NICAR.ORG/DATA 

15


# Bits, Bytes and Barks 

## Conference Audio Tapes 

Audio tapes from the March 1998 sessions at Indiana CAR are now available for ordering from Sound Images, which can be reached at (303) 649-1811. For more infor- mation or a downloadable order form, point your browser to Audio tapes from the June 1998 IRE National Confer- ence in New Orleans are also available. For more informa- tion, point your browser to wwww.ire.org/resources/confer ences/neworleanslaudio.html. 

## Campaign Finance Information Center 

Campaign finance data from 13 states is freely downloadable from the CFIC at www.campaignfinance.org We also have links to sixteen online search engines hosted by other non-profits and state boards of election. We will soon release our "universal" online search engine so you can type in a contributor from your state and see where else they are giving. 

The more inclusive this database, the better for every- one. So, if you have state or local campaign data you want included, contact CFIC Coordinator Jack Dolan at jack@nicar.org or (573) 884-1802. The CFIC credits ev- eryone who contributes data. 

Other services available on the CFIC Web site in- clude a directory of campaign finance reporters, a col- lection of campaign finance stories and other suggested readings to generate story ideas, and information on joining the CFIC-L mailing list. 

## Moving On 

As posted to the IRE-L and NICAR-L mailing lists, investigative reporter Mike Wendland of WDIV in Detroit announced that he will be leaving the station, where he has worked since 1980. Ray Robinson, formerly with The Virginian-Pilot, has become an archive manager at the Associated Press head- quarters in New York where he will be responsibled for creating and managing a text and photo archive. If you have recently switched locales, let us know of your whereabouts. Send an e-mail to Brent Johnson at bjohnson@nicar.org 

## Conferences: The Next Wave 

Information on upcoming IRE and NICAR national and regional conferences is now available on the IRE Web site at www.ire.org/resources/conferences/index.html. 

NICAR's national conference, co-sponsored by the Boston Globe, will be held March 11-14, 1999 in Boston, Mass. IRE's national conference, co-sponsored by the Kan- sas City Star and KCTV, will be held June 3-6, 1999 in Kansas City, Mo. Downloadable registration forms and other information are posted on the site. 

For information on other events-including boot camps, on-the-road training, and an IRE regional conference to be held Sept. 9-12, 1999 in Los Angeles - point your browser to www.ire.org/calendar.htmL. 

OW 987 ON LINDED Alid "S"N LHOUR-NON 

11759 OW JO looy's unoss!W JO you 8EI pue 